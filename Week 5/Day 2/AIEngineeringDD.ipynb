{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block import necessary libraries for this project\n",
    "! pip install -qU langchain langchain_openai langgraph arxiv duckduckgo-search pubmed wolframalpha duckduckgo_search==5.3.1b1\n",
    "# !pip install -qU langchain langchain_openai langchain-community langchain_core qdrant_client langgraph arxiv duckduckgo_search==5.3.1b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To effectively present the purpose of my mental health bot on Demo Day, consider focusing on the following key aspects:\n",
    "\n",
    "1. **User Needs**: Highlight the specific mental health challenges your app addresses, such as anxiety, depression, or stress management.\n",
    "2. **Features**: Showcase the unique features of your app, like mood tracking, meditation exercises, or therapist connections.\n",
    "3. **Scientific Basis**: Emphasize any scientific research or evidence that supports the effectiveness of your app.\n",
    "4. **User Experience**: Discuss how your app provides a user-friendly and engaging experience.\n",
    "5. **Impact**: Share any success stories or data that demonstrate the positive impact your app has had on users' mental health.\n",
    "\n",
    "By covering these points, you can clearly convey the value and purpose of your mental health app to your audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU faiss-cpu pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "# Load papers on mental health and solutions\n",
    "docs = ArxivLoader(\n",
    "    query=\"mental health AND (treatment OR therapy OR intervention)\",\n",
    "    load_max_docs=10,\n",
    "    sort_by=\"submittedDate\",\n",
    "    sort_order=\"descending\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Published', 'Title', 'Authors', 'Summary']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supporting Therapeutic Relationships and Communication about Mental Health\n",
      "Abstract:  \n",
      "Supporting Therapeutic Relationships and \n",
      "Communication about Mental Health\n",
      " \n",
      "Introduction and background \n",
      "Effective communication and strong therapeutic \n",
      "relationships are critical to successful mental health \n",
      "interventions. For example, in 1957 Carl Rogers, a \n",
      "pioneer of person-centred therapy, ...\n",
      "=================================================================================\n",
      "Title: The Role of Mandated Mental Health Treatment in the Criminal Justice System\n",
      "Abstract: The Role of Mandated Mental Health Treatment in the\n",
      "Criminal Justice System\n",
      "Rachel Nesbit*\n",
      "November 14, 2023\n",
      "Abstract\n",
      "Mental health disorders are particularly prevalent among those in the criminal justice system\n",
      "and may be a contributing factor in recidivism. Using North Carolina court cases from 19...\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:2]:\n",
    "    print(f\"Title: {doc.metadata['Title']}\")\n",
    "    print(f\"Abstract: {doc.page_content[:300]}...\")  # Print first 300 characters of abstract\n",
    "    print(\"=================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports the necessary modules: os for interacting with the operating system and getpass for securely prompting the user for input without echoing the input to the console.\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the previous code block, this one prompts the user to enter their Wolfram Alpha App ID using getpass.getpass().\n",
    "import os\n",
    "\n",
    "os.environ[\"WOLFRAM_ALPHA_APPID\"] = getpass.getpass (\"WOLFRAM_ALPHA_APPID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE3 - LangGraphDemo -{'5a4498e2'}\"#{uuid4().hex[0:8]}\"# {'9dc7f3da'}\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5a4498e2'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{uuid4().hex[0:8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports necessary classes from langchain and langchain_community libraries.\n",
    "# It uses the ArxivLoader to load a maximum of 5 documents from arXiv related to the query \"Mental Health\".\n",
    "# The loaded documents are then split into chunks using the RecursiveCharacterTextSplitter with a chunk size of 500 characters and an overlap of 50 characters between chunks.\n",
    "# The chunked documents are then used to create a vector store using the FAISS class from langchain_community.\n",
    "# The OpenAIEmbeddings class is used to generate embeddings for the documents using the \"text-embedding-3-small\" model.\n",
    "# Finally, a retriever object is created from the faiss_vectorstore to enable retrieval of relevant documents based on queries.\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "docs = ArxivLoader(\n",
    "    query=\"\\\"mental health counseling\\\" AND (data OR analytics OR \\\"machine learning\\\")\",\n",
    "    load_max_docs=10,\n",
    "    sort_by=\"submittedDate\",\n",
    "    sort_order=\"descending\"\n",
    ").load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunked_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(\n",
    "    documents=chunked_documents,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports the ChatPromptTemplate class from langchain_core.prompts.\n",
    "# It defines a prompt template named RAG_PROMPT using a multi-line string. The prompt template includes placeholders for the user's question ({question}) and the relevant context ({context}).\n",
    "# The ChatPromptTemplate.from_template() method is used to create a prompt object named rag_prompt from the RAG_PROMPT template.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Your are a professional mental helth advisor. Use the following context to answer the user's query. If you cannot answer the question, please respond with 'I don't know'.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports the ChatOpenAI class from langchain_openai.\n",
    "# It creates an instance of the ChatOpenAI class named openai_chat_model with the model set to \"gpt-3.5-turbo\".\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Parent Document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain.storage import InMemoryStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "client.create_collection(\n",
    "    collection_name=\"split_parents\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vectorstore = Qdrant(client, collection_name=\"split_parents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=RecursiveCharacterTextSplitter(chunk_size=400),\n",
    "    parent_splitter=RecursiveCharacterTextSplitter(chunk_size=2000),\n",
    ")\n",
    "parent_document_retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports necessary classes and functions from langchain.\n",
    "# It creates a retrieval-augmented generation chain named retrieval_augmented_generation_chain.\n",
    "# The chain is defined using the LCEL (LangChain Expression Language) syntax.\n",
    "# It starts by retrieving the context based on the user's question using the retriever object and the itemgetter function.\n",
    "# The retrieved context is then assigned to the context variable using the RunnablePassthrough.assign() method.\n",
    "# The rag_prompt is then used to generate a response using the openai_chat_model based on the user's question and the retrieved context.\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "def create_qa_chain(retriever):\n",
    "\n",
    "  mentahealth_qa_llm =openai_chat_model\n",
    "\n",
    "  created_qa_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever,\n",
    "     \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | RunnablePassthrough.assign(\n",
    "        context=itemgetter(\"context\")\n",
    "      )\n",
    "    | {\n",
    "         \"response\": rag_prompt | mentahealth_qa_llm | StrOutputParser(),\n",
    "         \"context\": itemgetter(\"context\"),\n",
    "      }\n",
    "\n",
    "  )\n",
    "  return created_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Amod/mental_health_counseling_conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Context', 'Response'],\n",
       "        num_rows: 2809\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Context', 'Response'],\n",
       "        num_rows: 351\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Context', 'Response'],\n",
       "        num_rows: 352\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "ds_train_test=ds['train'].train_test_split(train_size=0.8)\n",
    "ds_test_valid=ds_train_test['test'].train_test_split(test_size=.5)\n",
    "mental_health_counseling_data= DatasetDict({\n",
    "\n",
    "    'train': ds_train_test['train'],\n",
    "    'validation': ds_test_valid['train'],\n",
    "    'test': ds_test_valid['test']\n",
    "\n",
    "})\n",
    "\n",
    "mental_health_counseling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"I don't know.\",\n",
       " 'context': [Document(metadata={'Published': '2024-06-13', 'Title': 'Enhancing Psychotherapy Counseling: A Data Augmentation Pipeline Leveraging Large Language Models for Counseling Conversations', 'Authors': 'Jun-Woo Kim, Ji-Eun Han, Jun-Seok Koh, Hyeon-Tae Seo, Du-Seong Chang', 'Summary': \"We introduce a pipeline that leverages Large Language Models (LLMs) to\\ntransform single-turn psychotherapy counseling sessions into multi-turn\\ninteractions. While AI-supported online counseling services for individuals\\nwith mental disorders exist, they are often constrained by the limited\\navailability of multi-turn training datasets and frequently fail to fully\\nutilize therapists' expertise. Our proposed pipeline effectively addresses\\nthese limitations. The pipeline comprises two main steps: 1) Information\\nExtraction and 2) Multi-turn Counseling Generation. Each step is meticulously\\ndesigned to extract and generate comprehensive multi-turn counseling\\nconversations from the available datasets. Experimental results from both\\nzero-shot and few-shot generation scenarios demonstrate that our approach\\nsignificantly enhances the ability of LLMs to produce higher quality multi-turn\\ndialogues in the context of mental health counseling. Our pipeline and dataset\\nare publicly available\\nhttps://github.com/jwkim-chat/A-Data-Augmentation-Pipeline-Leveraging-Large-Language-Models-for-Counseling-Conversations.\"}, page_content='8\\nTrauma\\n6\\nBaseline models\\nWe use Llama2-7B, Llama3-70B as baseline models for gen-\\nerating multi-turn counseling dialogues.\\nWe chose these\\nmodels because they are open-sourced and easily repro-\\nducible. We also compare these results with the Llama2-7B\\nmodel that has been fine-tuned on the Counsel Chat dataset,\\nwhich is available on HuggingFace 3.\\nExperimental setting\\nWe evaluate two experimental settings: 1) zero-shot multi-\\nturn dialogue generation (see Figure 2 for example), 2) few-\\nshot multi-turn dialogue generation (see Figure 3 for ex-\\n3https://huggingface.co/NadunAnjanaka/Llama-2-7b-chat-\\nCounsellor\\nample). Results are compared within the same mental dis-\\norder category.\\nWe consider these settings because well-\\nconstructed synthetic multi-turn counseling data should im-\\nprove the model’s few-shot dialogue generation capabilities.\\nThe following is a transcript of a chat between a psy-\\nchotherapist and a client about depression. The client\\nstarts the conversation as [client] and the psychother-\\napist starts the conversation as [psychotherapist].\\nPlease complete new transcript about [Question].\\n[Question]\\n[client] I’m almost never happy. Half of the time,\\nI don’t feel anything. I find it easy to make myself\\nfeel nothing. I know I push people away because it’s\\neasier. I just want answers. I’m sick of feeling this\\nway. It’s ruining my relationships with people.\\n[psychotherapist]\\nFigure 2: Example of zero-shot prompt\\nAutomatic Evaluation\\nWe conduct an automatic evaluation using GPT-4o, the lat-\\nest model introduced by OpenAI. The evaluation prompt is\\ndescribed in Figure 4. We follow the LLM evaluation sug-\\ngested by [Chiang and Lee, 2023] for automatic evaluation\\nbased on prompting. The prompt involves rating two answers\\nfrom different models on a scale of 1 to 5, with higher values\\nindicating better answers.\\n6.2\\nResult\\nEvaluation of Zero-shot and Few-shot Performance\\nTable 3 presents the average scores evaluated by GPT-'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='countered in a relationship, specify what kind of relationship it is. It\\nmay be that the relationship with a partner or a friend or family member\\nhas encountered difficulties, rather than just saying that a relationship\\nhas encountered difficulties. The return format is a dict, where the field\\n“content\" is a list of dictionaries (the user answers each time as a dict\\nin “content\", AI Strategies and AI are the same dict in “content\"). The\\n“scene\" is the same as in the above example, do not change.\\nD\\nExamples of Scenarios\\nBreakups or Divorce\\nExample 1: Processing the\\nemotions and grief following the end of a long-term\\nrelationship. Example 2: Seeking guidance on how\\nto navigate a recent breakup and move forward.\\nConflicts or Communication Problems\\nExam-\\nple 1: Dealing with a misunderstanding or disagree-\\nment with a close friend or family member. Exam-\\nple 2: Seeking advice on resolving conflicts with a\\nromantic partner and improving communication.\\nCommunication Challenges\\nExample: Helping\\na person find effective ways to express their needs\\nand concerns to their partner, fostering open and\\nconstructive communication.\\nCoping with the Death of a Loved One\\nExam-\\nple 1: Navigating the stages of grief and finding\\nways to honor the memory of the deceased. Seek-\\ning support in managing the emotional impact of\\nlosing a close family member or friend.\\nDealing with the Loss of a Pet\\nExample 1: Pro-\\ncessing the deep sadness and emptiness after the\\ndeath of a beloved pet. Example 2: Seeking under-\\nstanding and comfort while grieving the loss of a\\nlong-time companion animal.\\nWork-related Stress and Burnout\\nExample 1:\\nCoping with excessive workload, pressure, and a\\ndemanding work environment. Example 2: Seek-\\ning strategies to manage stress and achieve a health-\\nier work-life balance.\\nFinancial Worries and Uncertainty\\nExample\\n1: Navigating financial challenges such as debt,\\njob loss, or unexpected expenses.\\nExample 2:\\nSeeking emotional support and practical advice'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='Financial Worries and Uncertainty\\nExample\\n1: Navigating financial challenges such as debt,\\njob loss, or unexpected expenses.\\nExample 2:\\nSeeking emotional support and practical advice\\nto alleviate financial stress and regain stability.\\nUnemployment-related stress\\nExample: En-\\ncouraging someone who is about to lose their job\\ndue to poor company performance, discussing the\\npossibility of changing jobs, prioritizing self-care,\\nand staying positive.\\nAcademic Stress\\nExample: Offering guidance\\nand study tips to a student feeling overwhelmed by\\ntheir workload, helping them create a study plan\\nand adopt healthy stress management techniques.\\nDepression and Low Mood\\nExample 1: Deal-\\ning with feelings of sadness, loss of interest, and\\nlack of motivation. Example 2: Seeking guidance\\non coping mechanisms and professional help for\\nmanaging depression symptoms.\\nManaging Bipolar Disorder\\nExample 1: Find-\\ning support and strategies to navigate the highs and\\nlows of bipolar disorder. Example 2: Seeking ad-\\nvice on maintaining stability, managing medication,\\nand recognizing warning signs.\\nAnxiety and Panic\\nExample: Providing guid-\\nance and techniques for someone who experiences\\nsocial anxiety, helping them gradually face their\\nfears and build confidence in social situations.\\nDepression and Low Mood\\nExample: Being\\nthere for a person experiencing depression, actively\\nlistening to their struggles, and encouraging them\\nto seek professional help and engage in self-care\\nactivities.\\nAdjusting to a New Job or Role\\nExample 1:\\nCoping with the challenges and expectations of a\\nnew job or promotion. Example 2: Seeking guid-\\nance on adapting to a new work environment and\\nbuilding professional relationships.\\nMoving to a New City or Country\\nExample 1:\\nDealing with feelings of homesickness, cultural ad-\\njustment, and building a new social network. Exam-\\nple 2: Seeking support in navigating the practical\\nand emotional aspects of relocating to a different\\ncity or country.\\nCareer Transitions'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='tant: “Taking care of your mental health is crucial,\\nand it’s not something to feel guilty about. Your\\nwell-being should always be a priority, and I’m\\nglad you recognized that. Is there anything I can\\ndo to support you during this time?\"\\nSuggest Options (SO)\\nOffer practical sugges-\\ntions or alternative perspectives for addressing the\\nissue at hand. Example: User: “I’m having trou-\\nble managing my stress.\" Assistant: “Have you\\nconsidered trying relaxation techniques like deep\\nbreathing or mindfulness exercises?\"\\nCollaborative Planning (CP)\\nWork together\\nwith the User to develop an action plan. Exam-\\nple: User: “I want to improve my time manage-\\nment skills.\" Assistant: “Let’s brainstorm some\\nstrategies together. How about breaking tasks into\\nsmaller, more manageable chunks?\"\\nProvide Different Perspectives (PDP)\\nOffer al-\\nternative ways of looking at the situation to help\\nthe User gain new insights. Example: User: “I’m\\ndevastated that my project didn’t succeed.\" Assis-\\ntant: “Sometimes setbacks can lead to unexpected\\nopportunities for learning and growth. It’s a chance\\nto reassess and try again.\"\\nReframe Negative Thoughts (RNT)\\nHelp the\\nUser reframe negative thoughts into more positive\\nor realistic ones. Example: User: “I’m such a fail-\\nure.\" Assistant: “Instead of thinking that way, let’s\\nfocus on what you’ve learned from this experience\\nand how you can apply it moving forward.\"\\nShare Information (SI)\\nProvide educational or\\nfactual information about emotions, coping mecha-\\nnisms, or self-care practices. Example: User: “I’m\\nstruggling to manage my anxiety.\" Assistant: “Did\\nyou know that deep breathing exercises and ground-\\ning techniques can help reduce anxiety symptoms?\\nWould you like me to explain how to practice\\nthem?\"\\nNormalize Experiences (NE)\\nExplain that cer-\\ntain emotions or reactions are common and part of\\nthe human experience. Example: User: “I feel so\\nguilty for taking time for myself.\" Assistant: “It’s')]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_retriever_qa_chain = create_qa_chain(parent_document_retriever)\n",
    "await parent_document_retriever_qa_chain.ainvoke({'question': mental_health_counseling_data[\"test\"][2]['Context']})\n",
    "# output['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-17 12:39:00 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-07-17 12:39:02 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': \"It's understandable to feel sad after losing people who made you happy. It's important to focus on self-care and activities that bring you joy and relaxation. Engage in hobbies, exercise, spend time in nature, or connect with supportive friends or family members. It may also be helpful to seek professional counseling or therapy to work through your emotions and develop coping strategies. Remember, it's okay to seek help and take time to heal.\",\n",
       " 'context': [Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='Example 1: Processing the\\nemotions and grief following the end of a long-term\\nrelationship. Example 2: Seeking guidance on how\\nto navigate a recent breakup and move forward.\\nConflicts or Communication Problems\\nExam-\\nple 1: Dealing with a misunderstanding or disagree-\\nment with a close friend or family member. Exam-\\nple 2: Seeking advice on resolving conflicts with a\\nromantic partner and improving communication.\\nCommunication Challenges\\nExample: Helping\\na person find effective ways to express their needs\\nand concerns to their partner, fostering open and\\nconstructive communication.\\nCoping with the Death of a Loved One\\nExam-\\nple 1: Navigating the stages of grief and finding\\nways to honor the memory of the deceased. Seek-\\ning support in managing the emotional impact of\\nlosing a close family member or friend.\\nDealing with the Loss of a Pet\\nExample 1: Pro-\\ncessing the deep sadness and emptiness after the\\ndeath of a beloved pet. Example 2: Seeking under-\\nstanding and comfort while grieving the loss of a\\nlong-time companion animal.\\nWork-related Stress and Burnout\\nExample 1:\\nCoping with excessive workload, pressure, and a\\ndemanding work environment. Example 2: Seek-\\ning strategies to manage stress and achieve a health-\\nier work-life balance.\\nFinancial Worries and Uncertainty\\nExample\\n1: Navigating financial challenges such as debt,\\njob loss, or unexpected expenses.\\nExample 2:\\nSeeking emotional support and practical advice\\nto alleviate financial stress and regain stability.\\nUnemployment-related stress\\nExample: En-\\ncouraging someone who is about to lose their job\\ndue to poor company performance, discussing the\\npossibility of changing jobs, prioritizing self-care,\\nand staying positive.\\nAcademic Stress\\nExample: Offering guidance\\nand study tips to a student feeling overwhelmed by\\ntheir workload, helping them create a study plan\\nand adopt healthy stress management techniques.\\nDepression and Low Mood\\nExample 1: Deal-\\ning with feelings of sadness, loss of interest, and\\nlack of motivation. Example 2: Seeking guidance\\non coping mechanisms and professional help for\\nmanaging depression symptoms.\\nManaging Bipolar Disorder\\nExample 1: Find-\\ning support and strategies to navigate the highs and'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='lack of motivation. Example 2: Seeking guidance\\non coping mechanisms and professional help for\\nmanaging depression symptoms.\\nManaging Bipolar Disorder\\nExample 1: Find-\\ning support and strategies to navigate the highs and\\nlows of bipolar disorder. Example 2: Seeking ad-\\nvice on maintaining stability, managing medication,\\nand recognizing warning signs.\\nAnxiety and Panic\\nExample: Providing guid-\\nance and techniques for someone who experiences\\nsocial anxiety, helping them gradually face their\\nfears and build confidence in social situations.\\nDepression and Low Mood\\nExample: Being\\nthere for a person experiencing depression, actively\\nlistening to their struggles, and encouraging them\\nto seek professional help and engage in self-care\\nactivities.\\nAdjusting to a New Job or Role\\nExample 1:\\nCoping with the challenges and expectations of a\\nnew job or promotion. Example 2: Seeking guid-\\nance on adapting to a new work environment and\\nbuilding professional relationships.\\nMoving to a New City or Country\\nExample 1:\\nDealing with feelings of homesickness, cultural ad-\\njustment, and building a new social network. Exam-\\nple 2: Seeking support in navigating the practical\\nand emotional aspects of relocating to a different\\ncity or country.\\nCareer Transitions\\nExample: Assisting some-\\none who is considering a career change, helping\\nthem explore their passions, transferable skills, and\\ndevelop a plan for transitioning into a new field.\\nParenthood and Parenting Challenges\\nExam-\\nple: Supporting a new parent who is feeling over-\\nwhelmed and sleep-deprived, offering reassurance,\\nand sharing tips for self-care and coping strategies\\nfor the demands of parenthood.\\nLow Self-Esteem or Lack of Confidence\\nExam-\\nple 1: Addressing negative self-perceptions and\\nbuilding self-worth. Example 2: Seeking tech-\\nniques for cultivating self-compassion and improv-\\ning self-esteem.\\nBody Image Concerns and Eating Disorders\\nExample 1: Dealing with body dissatisfaction and\\nthe impact it has on self-image and overall well-\\nbeing. Example 2: Seeking support in recovering\\nfrom an eating disorder and developing a healthy\\nrelationship with food and body.\\nLGBTQ+ Identity\\nExample: Assisting someone'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='Post-Traumatic Stress Disorder (PTSD)\\nExam-\\nple: Creating a safe and non-judgmental space for\\na military veteran with PTSD to share their experi-\\nences and providing resources for trauma-focused\\ntherapy and support groups.\\nHealing from Abuse\\nExample: Assisting some-\\none who has recently left an abusive relationship,\\nconnecting them with local support services, and\\noffering encouragement as they rebuild their life.\\nNavigating Gender Identity and Transitioning\\nExample 1: Seeking support and resources while\\nexploring gender identity and considering transi-\\ntioning. Example 2: Accessing guidance on navi-\\ngating social, medical, and legal aspects of transi-\\ntioning.\\nChronic Illness or Pain Management\\nExample\\n1: Coping with the emotional impact of a chronic\\nillness, including pain, limitations, and lifestyle\\nadjustments. Example 2: Seeking support in man-\\naging daily challenges, finding self-care strategies,\\nand connecting with others facing similar health\\nissues.\\nCoping with a Diagnosis or Medical Treatment\\nExample 1: Processing the emotions surrounding\\na new medical diagnosis and navigating treatment\\noptions. Example 2: Seeking emotional support\\nand practical guidance to cope with medical proce-\\ndures, side effects, and lifestyle changes.\\nCaregiver Support\\nExample: Offering guidance\\nand resources to a caregiver of an elderly parent,\\ndiscussing techniques for managing caregiver stress\\nand suggesting respite care options.\\nFinding Meaning and Purpose in Life\\nExample\\n1: Exploring questions related to the meaning of\\nlife, personal values, and finding purpose. Example\\n2: Assisting someone who is questioning their life’s\\npurpose and exploring different avenues for finding\\nmeaning, discussing their values and interests, and\\nencouraging self-reflection.\\nSpirituality and Faith\\nExample: Offering guid-\\nance and resources to someone who is questioning\\ntheir faith or seeking spiritual fulfillment, providing\\nsupport ass they explore their beliefs and values.\\nAddiction and Recovery\\nExample: Offering em-\\npathy and understanding to someone battling addic-\\ntion, discussing treatment options, and providing\\nemotional support during their journey to recovery.\\nSupport for Loved Ones or Friends\\nExample:\\nSupporting a parent who has a child dealing with'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='but it doesn\\'t seem to have any effect. I\\'m \\nnot sure how to approach the situation \\nwithout causing conflict.\\nThat\\'s a good idea. I\\'ll give that a try. \\nIt\\'s just been really stressful, and I don\\'t \\nwant it to affect our relationship as \\nroommates.\\n(Reflective Statements) That sounds really \\nirritating. It must be tough to constantly clean \\nup after someone else.\\n(Suggest Options) Maybe you could try setting up \\nsome agreed-upon rules for kitchen cleanliness. \\nThat way, both you and your roommate are on the \\nsame page.\\n(Normalize Experiences) It\\'s completely \\nnormal to have disagreements or conflicts \\nwith roommates. The key is finding a way to \\naddress the issues together that works for \\nboth of you.\\n... ...\\nFigure 3: An example chat showing effective emotional\\nsupport (adapted from our dataset) being provided to the\\nuser (left) by the assistant (right). The support strategies\\nused by the assistant are marked in parentheses before\\nthe utterances.\\nB\\nDefinitions of Strategies\\nReflective Statements (RS)\\nRepeat or rephrase\\nwhat the User has expressed to show that you’re ac-\\ntively listening. Example: User: “I’m feeling really\\noverwhelmed with all the work I have to do.\" As-\\nsistant: “It sounds like you’re feeling overwhelmed\\nwith your workload.\"\\nClarification (Cla)\\nSeek clarification to ensure\\na clear understanding of the User’s emotions and\\nexperiences. Example: User: “I just can’t shake\\noff this feeling of sadness.\" Assistant: “Could you\\nhelp me understand what might have triggered this\\nfeeling of sadness?\"\\nEmotional Validation (EV)\\nAcknowledge and\\nvalidate the User’s emotions without judgment. Ex-\\nample: User: “I’m so frustrated with myself for\\nmaking the same mistake again.\" Assistant: “It’s\\nFigure 4: Data example from our dataset.\\ncompletely understandable to feel frustrated when\\nyou make a mistake.\"\\nEmpathetic Statements (ES)\\nExpress under-'),\n",
       "  Document(metadata={'Published': '2023-08-17', 'Title': 'Building Emotional Support Chatbots in the Era of LLMs', 'Authors': 'Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie', 'Summary': 'The integration of emotional support into various conversational scenarios\\npresents profound societal benefits, such as social interactions, mental health\\ncounseling, and customer service. However, there are unsolved challenges that\\nhinder real-world applications in this field, including limited data\\navailability and the absence of well-accepted model training paradigms. This\\nwork endeavors to navigate these challenges by harnessing the capabilities of\\nLarge Language Models (LLMs). We introduce an innovative methodology that\\nsynthesizes human insights with the computational prowess of LLMs to curate an\\nextensive emotional support dialogue dataset. Our approach is initiated with a\\nmeticulously designed set of dialogues spanning diverse scenarios as generative\\nseeds. By utilizing the in-context learning potential of ChatGPT, we\\nrecursively generate an ExTensible Emotional Support dialogue dataset, named\\nExTES. Following this, we deploy advanced tuning techniques on the LLaMA model,\\nexamining the impact of diverse training strategies, ultimately yielding an LLM\\nmeticulously optimized for emotional support interactions. An exhaustive\\nassessment of the resultant model showcases its proficiency in offering\\nemotional support, marking a pivotal step in the realm of emotional support\\nbots and paving the way for subsequent research and implementations.'}, page_content='to prioritize your needs too.\"\\nPromote Self-Care Practices (PSP)\\nAdvocate\\nfor engaging in activities that promote well-being\\nand self-care. Example: “Make sure to take some\\ntime for yourself and do something that brings you\\njoy and relaxation.\"\\nStress Management (SM)\\nProvide suggestions\\nfor stress management techniques like exercise,\\nmeditation, or spending time in nature. Example:\\n“Engaging in regular physical activity can help re-\\nduce stress and improve mood.\"\\nOthers (Oth)\\nInteract with friendly greetings\\nand employ additional supportive techniques that\\nare not covered by the previously mentioned cate-\\ngories.\\nC\\nChatGPT Self-Chat Template\\nThe template for ChatGPT self-chat (Figure 1) is\\nas follows:\\nRemember here is a comprehensive list of typical strategies for respond-\\ning in conversations for emotional support, along with examples for\\neach: 1. Reflective Statements: Repeat or rephrase what the person has\\nexpressed to show that you’re actively listening. 2. Clarification: Seek\\nclarification to ensure a clear understanding of the person’s emotions\\nand experiences. 3. Emotional Validation: Acknowledge and validate\\nthe person’s emotions without judgment. 4. Empathetic Statements:\\nExpress understanding and empathy towards the person’s experiences.\\n5. Affirmation: Provide positive reinforcement and encouragement to\\nuplift the person’s spirits. 6. Offer Hope: Share optimistic perspectives\\nor possibilities to instill hope. 7. Avoid judgment and criticism: It’s\\nimportant to create a non-judgmental and safe space for the person to\\nexpress their emotions without fear of criticism. Refrain from passing\\njudgment or being overly critical of their experiences or choices. 8.\\nSuggest Options: Offer practical suggestions or alternative perspec-\\ntives for addressing the issue at hand. 9. Collaborative Planning: Work\\ntogether with the person to develop an action plan. 10. Provide Dif-\\nferent Perspectives: Offer alternative ways of looking at the situation\\nto help the person gain new insights. 11. Reframe Negative Thoughts:\\nHelp the person reframe negative thoughts into more positive or re-\\nalistic ones. 12. Share Information: Provide educational or factual')]}"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change of behavior of system! <You are a professional Mental Health Advisor> added.\n",
    "await create_qa_chain(retriever).ainvoke({\"question\" : mental_health_counseling_data[\"test\"][2]['Context']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sounds like no solution using research papers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install wolframalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports various tool classes from the langchain_community library.\n",
    "# It creates a list named tool_belt that contains instances of the following tools:\n",
    "# ArxivQueryRun(): A tool for running queries on the arXiv database.\n",
    "# DuckDuckGoSearchRun(): A tool for performing searches using the DuckDuckGo search engine.\n",
    "# The PubmedQueryRun() and WolframAlphaAPIWrapper() tools are commented out and not included in the tool_belt.\n",
    "\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun \n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "from langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def rag_tool(question: str) -> str:\n",
    "    \"\"\"Use this tool to retrieve relevant information from the knowledge base.\"\"\"\n",
    "    # advanced_rag_prompt=ChatPromptTemplate.from_template(INSTRUCTION_PROMPT_TEMPLATE.format(user_query=question))\n",
    "    parent_document_retriever_qa_chain = create_qa_chain(parent_document_retriever)\n",
    "    response=parent_document_retriever_qa_chain.invoke({'question': question})['response']\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "tool_belt = [\n",
    "    rag_tool,\n",
    "    # PubmedQueryRun,\n",
    "    ArxivQueryRun(),\n",
    "    DuckDuckGoSearchRun(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value not declarable with JSON Schema, field: name='callback_manager' type=Optional[BaseCallbackManager] required=False default=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[524], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This code block imports the ToolExecutor class from the langgraph.prebuilt module.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# It creates an instance of the ToolExecutor class named tool_executor and passes the tool_belt as an argument.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# The ToolExecutor is responsible for executing the tools in the tool_belt based on the provided input.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolExecutor\n\u001b[0;32m----> 6\u001b[0m tool_executor \u001b[38;5;241m=\u001b[39m \u001b[43mToolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_belt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langgraph/prebuilt/tool_executor.py:99\u001b[0m, in \u001b[0;36mToolExecutor.__init__\u001b[0;34m(self, tools, invalid_tool_msg_template)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     94\u001b[0m     tools: Sequence[Union[BaseTool, Callable]],\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m     96\u001b[0m     invalid_tool_msg_template: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m INVALID_TOOL_MSG_TEMPLATE,\n\u001b[1;32m     97\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute, afunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aexecute, trace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 99\u001b[0m     tools_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    100\u001b[0m         tool \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, BaseTool) \u001b[38;5;28;01melse\u001b[39;00m create_tool(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools\n\u001b[1;32m    101\u001b[0m     ]\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;241m=\u001b[39m tools_\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_map \u001b[38;5;241m=\u001b[39m {t\u001b[38;5;241m.\u001b[39mname: t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools}\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langgraph/prebuilt/tool_executor.py:100\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     94\u001b[0m     tools: Sequence[Union[BaseTool, Callable]],\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m     96\u001b[0m     invalid_tool_msg_template: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m INVALID_TOOL_MSG_TEMPLATE,\n\u001b[1;32m     97\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute, afunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aexecute, trace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     99\u001b[0m     tools_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 100\u001b[0m         tool \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, BaseTool) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcreate_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools\n\u001b[1;32m    101\u001b[0m     ]\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;241m=\u001b[39m tools_\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_map \u001b[38;5;241m=\u001b[39m {t\u001b[38;5;241m.\u001b[39mname: t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools}\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langchain_core/tools.py:1173\u001b[0m, in \u001b[0;36mtool\u001b[0;34m(return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, *args)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_with_name(args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;66;03m# if the argument is a function, then we use the function name as the tool name\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;66;03m# Example usage: @tool\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_make_with_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;66;03m# if there are no arguments, then we use the function name as the tool name\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;66;03m# Example usage: @tool(return_direct=True)\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_partial\u001b[39m(func: Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTool:\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langchain_core/tools.py:1134\u001b[0m, in \u001b[0;36mtool.<locals>._make_with_name.<locals>._make_tool\u001b[0;34m(dec_func)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infer_schema \u001b[38;5;129;01mor\u001b[39;00m args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStructuredTool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoroutine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_direct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_docstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# If someone doesn't want a schema applied, we must treat it as\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;66;03m# a simple string->string function\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dec_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langchain_core/tools.py:959\u001b[0m, in \u001b[0;36mStructuredTool.from_function\u001b[0;34m(cls, func, coroutine, name, description, return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m         filter_args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# schema name is appended within function\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     _args_schema \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_schema_from_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_docstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    967\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    968\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    975\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langchain_core/tools.py:291\u001b[0m, in \u001b[0;36mcreate_schema_from_function\u001b[0;34m(model_name, func, filter_args, parse_docstring, error_on_invalid_docstring)\u001b[0m\n\u001b[1;32m    285\u001b[0m description, arg_descriptions \u001b[38;5;241m=\u001b[39m _infer_arg_descriptions(\n\u001b[1;32m    286\u001b[0m     func,\n\u001b[1;32m    287\u001b[0m     parse_docstring\u001b[38;5;241m=\u001b[39mparse_docstring,\n\u001b[1;32m    288\u001b[0m     error_on_invalid_docstring\u001b[38;5;241m=\u001b[39merror_on_invalid_docstring,\n\u001b[1;32m    289\u001b[0m )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Pydantic adds placeholder virtual fields we need to strip\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m valid_properties \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filtered_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43minferred_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _create_subset_model(\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m     inferred_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     fn_description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[1;32m    298\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/langchain_core/tools.py:149\u001b[0m, in \u001b[0;36m_get_filtered_args\u001b[0;34m(inferred_model, func, filter_args)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_filtered_args\u001b[39m(\n\u001b[1;32m    143\u001b[0m     inferred_model: Type[BaseModel],\n\u001b[1;32m    144\u001b[0m     func: Callable,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    146\u001b[0m     filter_args: Sequence[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the arguments from a function's signature.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43minferred_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    150\u001b[0m     valid_keys \u001b[38;5;241m=\u001b[39m signature(func)\u001b[38;5;241m.\u001b[39mparameters\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    152\u001b[0m         k: schema[k]\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (k, param) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(valid_keys\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m filter_args \u001b[38;5;129;01mand\u001b[39;00m (i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m param\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    155\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/main.py:664\u001b[0m, in \u001b[0;36mBaseModel.schema\u001b[0;34m(cls, by_alias, ref_template)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cached\n\u001b[0;32m--> 664\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__schema_cache__[(by_alias, ref_template)] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/schema.py:188\u001b[0m, in \u001b[0;36mmodel_schema\u001b[0;34m(model, by_alias, ref_prefix, ref_template)\u001b[0m\n\u001b[1;32m    186\u001b[0m model_name_map \u001b[38;5;241m=\u001b[39m get_model_name_map(flat_models)\n\u001b[1;32m    187\u001b[0m model_name \u001b[38;5;241m=\u001b[39m model_name_map[model]\n\u001b[0;32m--> 188\u001b[0m m_schema, m_definitions, nested_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_process_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m nested_models:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# model_name is in Nested models, it has circular references\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     m_definitions[model_name] \u001b[38;5;241m=\u001b[39m m_schema\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/schema.py:581\u001b[0m, in \u001b[0;36mmodel_process_schema\u001b[0;34m(model, by_alias, model_name_map, ref_prefix, ref_template, known_models, field)\u001b[0m\n\u001b[1;32m    579\u001b[0m     s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m doc\n\u001b[1;32m    580\u001b[0m known_models\u001b[38;5;241m.\u001b[39madd(model)\n\u001b[0;32m--> 581\u001b[0m m_schema, m_definitions, nested_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_type_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m s\u001b[38;5;241m.\u001b[39mupdate(m_schema)\n\u001b[1;32m    590\u001b[0m schema_extra \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mschema_extra\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/schema.py:622\u001b[0m, in \u001b[0;36mmodel_type_schema\u001b[0;34m(model, by_alias, model_name_map, ref_template, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, f \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39m__fields__\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m \u001b[43mfield_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mknown_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipField \u001b[38;5;28;01mas\u001b[39;00m skip:\n\u001b[1;32m    631\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(skip\u001b[38;5;241m.\u001b[39mmessage, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/schema.py:255\u001b[0m, in \u001b[0;36mfield_schema\u001b[0;34m(field, by_alias, model_name_map, ref_prefix, ref_template, known_models)\u001b[0m\n\u001b[1;32m    252\u001b[0m     s\u001b[38;5;241m.\u001b[39mupdate(validation_schema)\n\u001b[1;32m    253\u001b[0m     schema_overrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m \u001b[43mfield_type_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_models\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# $ref will only be returned when there are no schema_overrides\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$ref\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f_schema:\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/schema.py:527\u001b[0m, in \u001b[0;36mfield_type_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m field\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01min\u001b[39;00m {SHAPE_SINGLETON, SHAPE_GENERIC}, field\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 527\u001b[0m     f_schema, f_definitions, f_nested_models \u001b[38;5;241m=\u001b[39m \u001b[43mfield_singleton_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mknown_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     definitions\u001b[38;5;241m.\u001b[39mupdate(f_definitions)\n\u001b[1;32m    537\u001b[0m     nested_models\u001b[38;5;241m.\u001b[39mupdate(f_nested_models)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai3/lib/python3.10/site-packages/pydantic/v1/schema.py:951\u001b[0m, in \u001b[0;36mfield_singleton_schema\u001b[0;34m(field, by_alias, model_name_map, ref_template, schema_overrides, ref_prefix, known_models)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m Generic \u001b[38;5;129;01min\u001b[39;00m field_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m:\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_schema, definitions, nested_models\n\u001b[0;32m--> 951\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue not declarable with JSON Schema, field: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Value not declarable with JSON Schema, field: name='callback_manager' type=Optional[BaseCallbackManager] required=False default=None"
     ]
    }
   ],
   "source": [
    "# This code block imports the ToolExecutor class from the langgraph.prebuilt module.\n",
    "# It creates an instance of the ToolExecutor class named tool_executor and passes the tool_belt as an argument.\n",
    "# The ToolExecutor is responsible for executing the tools in the tool_belt based on the provided input.\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tool_belt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports the ChatOpenAI class from the langchain_openai module.\n",
    "# It creates an instance of the ChatOpenAI class named model with the temperature parameter set to 0.\n",
    "# The temperature parameter controls the randomness of the generated responses. A value of 0 means the model will generate deterministic responses.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports the convert_to_openai_function function from the langchain_core.utils.function_calling module.\n",
    "# It creates a list named functions by applying the convert_to_openai_function function to each tool in the tool_belt.\n",
    "# The convert_to_openai_function function converts the tools into a format compatible with OpenAI's function calling API.\n",
    "# It then binds the converted functions to the model using the bind_functions() method, allowing the model to utilize the tools during generation.\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "functions = [convert_to_openai_function(t) for t in tool_belt]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This code block imports necessary types and classes from the typing module and the langchain_core.messages module.\n",
    "# It defines a custom type named AgentState using the TypedDict class from the typing module.\n",
    "# The AgentState type has a field named messages of type Annotated[Sequence[BaseMessage], operator.add].\n",
    "# Sequence[BaseMessage] indicates that messages is a sequence of BaseMessage objects.\n",
    "# Annotated is used to attach metadata to the type, in this case, specifying that the messages field should be treated as a concatenable sequence using the operator.add function.\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block imports necessary classes and functions from the langgraph.prebuilt, json, and langchain_core.messages modules.\n",
    "# It defines two functions: call_model and call_tool.\n",
    "# The call_model function takes the state as input, extracts the messages from the state, invokes the model with the messages, and returns a dictionary containing the response message.\n",
    "# The call_tool function takes the state as input, extracts the last message from the state, creates a ToolInvocation object using the tool name and arguments from the last message, invokes the tool_executor with the ToolInvocation, creates a FunctionMessage object with the tool response and name, and returns a dictionary containing the FunctionMessage.\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "def call_model(state):\n",
    "  messages = state[\"messages\"]\n",
    "  response = model.invoke(messages)\n",
    "  return {\"messages\" : [response]}\n",
    "\n",
    "def call_tool(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  action = ToolInvocation(\n",
    "      tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "      tool_input=json.loads(\n",
    "          last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "      )\n",
    "  )\n",
    "\n",
    "  response = tool_executor.invoke(action)\n",
    "\n",
    "  function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "  return {\"messages\" : [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompiledStateGraph(nodes={'__start__': PregelNode(config={'tags': ['langsmith:hidden'], 'metadata': {}}, channels=['__start__'], triggers=['__start__'], writers=[ChannelWrite<messages>(recurse=True, writes=[ChannelWriteEntry(channel='messages', value=<object object at 0x7efba009c3a0>, skip_none=False, mapper=_get_state_key(recurse=False))], require_at_least_one_of=['messages']), ChannelWrite<start:agent>(recurse=True, writes=[ChannelWriteEntry(channel='start:agent', value='__start__', skip_none=False, mapper=None)], require_at_least_one_of=None)]), 'agent': PregelNode(config={'tags': [], 'metadata': {}}, channels={'messages': 'messages'}, triggers=['action', 'start:agent'], mapper=functools.partial(<function _coerce_state at 0x7efba0132950>, <class '__main__.AgentState'>), writers=[ChannelWrite<agent,messages>(recurse=True, writes=[ChannelWriteEntry(channel='agent', value='agent', skip_none=False, mapper=None), ChannelWriteEntry(channel='messages', value=<object object at 0x7efba009c3a0>, skip_none=False, mapper=_get_state_key(recurse=False))], require_at_least_one_of=['messages']), _route(recurse=True, _is_channel_writer=True)]), 'action': PregelNode(config={'tags': [], 'metadata': {}}, channels={'messages': 'messages'}, triggers=['branch:agent:should_continue:action'], mapper=functools.partial(<function _coerce_state at 0x7efba0132950>, <class '__main__.AgentState'>), writers=[ChannelWrite<action,messages>(recurse=True, writes=[ChannelWriteEntry(channel='action', value='action', skip_none=False, mapper=None), ChannelWriteEntry(channel='messages', value=<object object at 0x7efba009c3a0>, skip_none=False, mapper=_get_state_key(recurse=False))], require_at_least_one_of=['messages'])])}, channels={'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x7efbdf70bc10>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x7efbdf70b820>, 'agent': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x7efbdf782710>, 'action': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x7efbdf782500>, 'start:agent': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x7efbdf781d80>, 'branch:agent:should_continue:action': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x7efbdf7804f0>}, auto_validate=False, stream_mode='updates', output_channels=['messages'], stream_channels=['messages'], input_channels='__start__', builder=<langgraph.graph.state.StateGraph object at 0x7efbdf70af20>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code block imports the StateGraph and END classes from the langgraph.graph module.\n",
    "# It creates an instance of the StateGraph class named workflow with the AgentState type.\n",
    "# It adds two nodes to the workflow using the add_node() method:\n",
    "# The \"agent\" node is associated with the call_model function.\n",
    "# The \"action\" node is associated with the call_tool function.\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "workflow.set_entry_point('agent')\n",
    "\n",
    "#-------------------------------\n",
    "# This code block defines a function named should_continue that takes the state as input.\n",
    "# The should_continue function checks the last message in the state to determine whether to continue or end the workflow.\n",
    "# If the last message does not have a \"function_call\" in its additional_kwargs, it returns \"end\".\n",
    "# Otherwise, it returns \"continue\".\n",
    "# It adds conditional edges to the workflow using the add_conditional_edges() method.\n",
    "# The conditional edges originate from the \"agent\" node and are based on the should_continue function.\n",
    "# If the should_continue function returns \"continue\", the workflow transitions to the \"action\" node.\n",
    "# If the should_continue function returns \"end\", the workflow transitions to the END node, indicating the end of the workflow.\n",
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if \"function_call\" not in last_message.additional_kwargs:\n",
    "    return \"end\"\n",
    "\n",
    "  return \"continue\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\" : \"action\",\n",
    "        \"end\" : END\n",
    "    }\n",
    ")\n",
    "# --------------------------------------------\n",
    "\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-------------------------------\n",
    "# This code block defines a function named should_continue that takes the state as input.\n",
    "# The should_continue function checks the last message in the state to determine whether to continue or end the workflow.\n",
    "# If the last message does not have a \"function_call\" in its additional_kwargs, it returns \"end\".\n",
    "# Otherwise, it returns \"continue\".\n",
    "# It adds conditional edges to the workflow using the add_conditional_edges() method.\n",
    "# The conditional edges originate from the \"agent\" node and are based on the should_continue function.\n",
    "# If the should_continue function returns \"continue\", the workflow transitions to the \"action\" node.\n",
    "# If the should_continue function returns \"end\", the workflow transitions to the END node, indicating the end of the workflow.\n",
    "def get_state_update_bot():\n",
    "\n",
    "  workflow = StateGraph(AgentState)\n",
    "\n",
    "  workflow.add_node(\"agent\", call_model)# agent node has access to llm\n",
    "  workflow.add_node(\"action\", call_tool)# action node has access to tools\n",
    "  workflow.set_entry_point('agent')\n",
    "  workflow.add_conditional_edges(\n",
    "      \"agent\",\n",
    "      should_continue,\n",
    "      {\n",
    "          \"continue\" : \"action\",#tools\n",
    "          \"end\" : END\n",
    "      }\n",
    "  )\n",
    "  workflow.add_edge(\"action\", \"agent\")#tools\n",
    "  state_update_bot=workflow.compile()\n",
    "\n",
    "  return state_update_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADuAPMDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAYIBQcBAwQCCf/EAFMQAAEDBAADAgcJDAUJCQAAAAEAAgMEBQYRBxIhEzEIFBUWIkHRMlFTVVaSk5TTFyM1NlRhcXWBlbPUCUJ2kaEkNENSYnKCtMEYJTNEV2ODhbH/xAAaAQEBAAMBAQAAAAAAAAAAAAAAAQIDBAUG/8QAMhEBAAECAQkGBgIDAAAAAAAAAAECEQMEEiExUVJhodEFExRBkcEjMnGBsfAVM0JT4f/aAAwDAQACEQMRAD8A/VNERAREQEREBERARdFbWQW6kmqqmRsNPC0vfI7uaB3lR1lqrcuaKi6S1dutjxuK1RPMMj2+p072nm3/AO21wAB07m7htoovGdVNo/dS2ZyrvVvt7+Sqr6amf/qzTNYf8SvP51WT44oPrTPaumjwfHbfHyU1htsLfXyUkYJ9fU66nfXZXf5rWX4ooPqzPYs/g8eRocedVk+OKD60z2p51WT44oPrTPaufNay/FFB9WZ7E81rL8UUH1ZnsT4PHkuhx51WT44oPrTPannVZPjig+tM9q581rL8UUH1ZnsTzWsvxRQfVmexPg8eRocedVk+OKD60z2rluU2ZxAbd6Ak9wFSz2p5rWX4ooPqzPYuDitkcCDZ6Ag9CDSs9ifB48jQyUcrJmB8b2vY7uc07BX2o3JgVrgkM9pY6wVmwe2toETXa6afHrkeNdPSaT7xBAK9dkvFRNUy225xshusDA8uiBENTGToSxbJIG+jmEksPQkgse/GaKZjOom/5S2xmURFpQREQEREBERAREQEREBERAREQEREBERBGMm1c8jx+yv06CR0txnYd+myAs5R9LLE7/gUnUZu7fFc9x2rcD2U9LV0GwNjtHdlK3Z9XowSKTLoxPkoiNnvKzqgRa/PhCcLGkg8SsPBHQg36l+0X1J4QPC6GRzH8ScQY9pLXNdfaUEEd4I7Rc6PNZ+OFuyLPrljFqx/Ibiy21r7bWXuCjYbfBVMiEroXPMgeCAWjfJy8zgObqFGOB/Hm98RMbym53vDb1QC01txZG+Cnhc2aOCd7G07GMnke+oDW6cNcpcDykjSwE2LZLfOOVmyvDsX83bZUV7Ki6ZVRXyGa3ZBbOwPKXUrHEulO2ckhb6IG+cggDz27BuJ9lwLilgtotLrVVXCru9yseVwXKFscpqagzRxcgPaxSake3nLdNLQQT0QTy1eEdZqyHJ23PHckxm5WC0SX2a1XmjjiqaijYHblh5ZHMd1YW6LgQSAdKI5/wCFHcaXhVTZfi2EZA6lrK61xUlVc6WnZHUwVUzWufGw1Afvl9BpcAOeWI9WEuEDoOBeRw3zJ6+x8LWYdbrtgNzx0Uxu1NPVS17+R8ck7g8hwfosD+dztjb+UFbW4h8NMjvvg02TG7ZRRSZNaqez1LbfNO1jZZaOWnlfD2my0E9k5odvl2R111Qbcx67TX2y0lfUWutss07eZ1Bcez7eHqRp/ZvezfTfouPesiteU/G/GrRRU0ecXWzcPr/KwySWK93yjFREzmcGOJbIWkODdggn3vUvv/tC8K//AFLw/wDf1L9og2AoxnerfSUF7Zps9sq4nF3vwyPbHM38/oOLtHpzMb3a2Pdi+Z4/nFBJXY5fbbkFFHKYX1Nrq46mNsgAJYXMJAdpzTrv0R768PEceMYtLQt2Za+eCjYAN9XytBP6A3mcfzNK6Mn/ALaY48vPkyp1pOiIudiIiICIiAiIgIiICIiAiIgIiICIiAiIgxt/srL9bXUzpDBK17JoJ2jbopWODmPHv6IGx6xsHoSvNZsjFTUC23ER0N7Y3b6Xm6Sgd8kJPu2fn7xvTtFZteG72Sgv1L4vcKWOqiB5miQdWu9TmnvafzjRW6mqLZler8Lfyl2+TaT8lh+jHsTybSfksH0Y9iwAwRsILaW/X2lj1oMFcZeX9BlDz/iuPMif5U376eL7JZZmHv8AKS0bUoa0MaGtAa0DQA7guVFvMif5U376eL7JPMif5U376eL7JO7w9/lK2jalKKvvg5XnIOKlizCsvWT3Vstqym42en8VfGwGCBzQzm2w7d1Oz/gts+ZE/wAqb99PF9knd4e/yktG1I5aOnndzSQRyO7tvYCV8eTKP8kg+jHsUf8AMif5U376eL7JcjCJvXlF+cPe7eIf/kad3h7/ACktG1nampobJRyTzyQUNKzq+R5EbB6up7veCw1uglyO7U95qoH09FSh3k6nnY5kvM4Frp5GnRaS0lrWkbDXO5uruVnbQYRa6KrjrJWz3KtjIdHU3GofUOjOtbYHkhh1vq0DvPvlZ9SaqKItRpmfP9/eCaI1CIi0IIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgrv4FH4p8SP7fXn+IxWIVd/Ao/FPiR/b68/xGKxCAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiCu/gUfinxI/t9ef4jFYhV38Cj8U+JH9vrz/EYrEICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAi8V5u9PYrdLW1POY2crQ2NvM97nENa1o9ZLiAB75UXdkGWTHnitdop2HqI5q2R7wP9otj1v8w2Pzlb8PBrxIvGrjNlsmqqP/SS8FJuJfBeDJrdG+a64e+Ws7Jp3z0kgaKjp77ezjfv1Njd76sD5czD8hsf1qb7NdVVcsqrqWamqLZYJ6eZhjkikqJi17SNEEdn1BB0tvha9sesFn5IeBfwN+7rxxtFuq6ftcetZFzupc3bHwxuGoj6vvjy1mu/lLiO5ftWq1+DtwDq/But2Q0tgprTVuvFe6qfUVNRL2jIRsQwbEfpNYC7qepL3H16G3fLmYfkNj+tTfZp4WvbHrBZN0UI8uZh+Q2P61N9mspY8oqai4ttt2pIqKukY6SB9PKZYZ2tI5gHFrS142DykdQdtLuV3LjVk9dMX0T9JgskaIi5UEREBERAREQEREBERAREQEREBERAREQEREBERBEeJR/7stI9Ru1Hsf8Aygr1rycSvwZaP1tSfxAsXxAyCmxXB79d6u7R2KCjopZTc5Ye2bTENOpOz/r6OjyDq7u9a9Kj+mn6z7L5M+iqfZeOXEHFJ81pbjHecgNJh8+S2o5FaKagqXSRPDC3s6Zx3EedrtPDZBykfnXTFxxybCbhebrJnMXEqzW/BpcheylpaaGGGtdLE2KN7oWbDHDnLQXcwAeTzdCMM+EW2RVxwLKeMDMitM11o75X2Otp533Ka70FrpYKF3YufFJTGmqHyObzhreWQPOnb5theHh5xEz+Gw8FspvuVi+UuaTxW+vtZt0EEcTpKSWWOaN7Gh4eHQ+ltxaeY8rWDQFzhZpkjJC4Nc1xaeVwB3o+8f7wsPdTrLsO166+YH9HidQf+gWmvBVx67W+XiBVVmU191pW5Zd6Y0NRT0zI3TNqBuoLo4mv53aO2h3IOY6aOmtyXb8bsM/WE3/J1C3YU3vPCr8SsJ8iIvJQREQEREBERAREQEREBERAREQEREBERAREQEREER4lfgy0frak/iBeDNcPtmf4pdccvMTprZcoHU87GPLHcp9bXDuIOiD74CkOY2eS82XkgfGypppoquEynlYXRvD+Vx0dBwBbvR1vejpa6wrjdjXEOzG6Y/5Ru1G2V0EktDQS1LGSN1zML4muYSNjucQd7BI6r08GO8wopp0zEz7MtcaEcn4AQ2qW53+DI8qyHKJLHV2Zk9ddo4pJ4ZACyMPbEGwua9oc2RjQ4OJLufuUE4LcI8wttzqrJeLLXWvh3W22opbpZ7/VWyp8akeGtZ2PiMMZa0N7QOLzshw6Aja37550/wAVX79yVf2aeedP8VX79yVf2az8PXuyZs7EYwXgnTYHJyQ5ZlV2t8dI+hpbbdbi2anpYna0GNDGlxaGgNdIXkDoD1K+6DgfYrdjGAWKOruLqTCqqGrt73yR9pK+OGSFomPJpw5ZXE8ob1A7u45KycV7Bk0NTLZ/KN1ipah9JO+htlRM2KZnu4nFrDyvbsbaeo31WS886f4qv37kq/s1e4r3ZM2djDYrwmoMMzK93613e7xQXiokrKmyPqGOoBUycvaTtYWc4e7l2fT5dk9Fnbt+N2GfrCb/AJOoXX550/xVfv3JV/ZqPXfiVYLPxFwqhyCokx91xqJo7SLjA+N1bVcnZ9mNj736Mp0XlvMXANB6qxTOFEzVFotPOJgiJjW3GiIvHYiIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAsFnOZW/h7iN1yS6tqXW62wGeZtHTunlLR6msaCSeo/MO8kAEjCcTOIN1wqkszrDiNxzSquNzjt7oba9jW0rSSZJZXuOmNa1ru/pzaaS3e12YrwzZjWe5VlUl/vN2qb6Ymtoq2qLqWhhjb6McMQ0B6Tnu2evpa98uDHW6iyPO8mw/MqbILljeKi2maoxGqtzIqmeokadeMvdtzeQO9w3+s3fMVPLdbaS0UcdJQ0sNFSx75IKeMRsbsknTQABskn9q9KIC0x4XPG5vAbgjer7BMI73VDyfaR0341I06fo/6jQ5/Xv5NetbnWnfCH8FvFfCXjsMeUXG9UUdmM7oGWmoiiEhl7PmLw+N+yOzGta1zO799Aob/Rq8eX4TxXq8Ju9WfJWWEGB8z+kde0EsOyf9I3bD6y4Rhfqovzo8GbwE8F4hUWSXuqvuUW25Y/lldbKGa21kEZYymkZ2Uh5oHffNnZI0NgaAX6LoC6aijp6zsu3gjn7J4lj7RgdyPHc4b7iN967kQapqrXknBu153k1LXZHxNZWVLa+hxhxiM1JzP++x079Almncwj9Qj00FziTsHH8hgv8AbLdVdjPb6ispI6zydXNEdVCx4B1JHs8rgToj1EELKqI3bhVjN54h2bOqm3E5TaaeSlpa+Od7D2Lw4GN7QeV7fTcQHA6J2EEuRantvFK6cMcPdcONlfjuOSyXfydR3C2zSmlqWPG4XOD27iOg8HZ0AwuJA7trMe2VjXscHscNtc07BHvhB9IiICIiAiIgIiICIiAuvxiL4RnzguxajznN7Tw7xqpvl6mfFRwFjAyGMySyyPcGsjjYOrnucQAB76DbHjEXwjPnBPGIvhGfOCr8/jjb7di9zvl9xzI8ZhonwxMprpQtE9ZJK7lijgbG94ke52hy7BBI3peCbwjsfttlyKtvNovthrLDDBVVlpuNIxtX2E0nZsmja2RzZGc2weVxILSCN6BCyHjEXwjPnBPGIvhGfOCrseOcE8eRUceNX233+2Wl13gtlzpoo5KyDZaJI9S60HAAte5jhsbAUMl483qt8G6izKutN9xy41NPRdpcqOhpKlrTK1jjUxQvqNGAk8oDyHjnHo9DoLb1dypKCmlqKmqhp6eJpfJLJIGta0d5JPcFDKrKMnuefWOks9pttTgNVb31VdkElx5ZudwIiigiaN79y4uJ1yuOiCADqvKPCEs+L3nKLe7H8iuYxjs33ert9HG+ClifAyYSlzpGlzQxx2GgvHI48utEyqx8RrTkWXV+PUInlqKS3Ut0NTyt7CSGoMgj5DvZP3pxO2jvHU+oJrwx4a4zwhxnyFjcT6eidUSVcr6mpfPNPM87fI97yS5x0P7lLfGIvhGfOCrjR+ETY7vjuN3K0WW/Xusv1K+upbPQUsb6xlO13I6WXcgjY0OIGy/qTobO9TTBs5tvEKwi62wVETGzSU09NWRGKemnjcWyRSMPVr2kaI/aCQQUG3kREBERBXbwKPxS4kf2+vP8RisSq7eBR+KXEj+315/iMViUBERAREQeG92K25LbJ7bd7fS3S3zgCWlrIWyxP0djbXAg6IB/YoXV41k2O8Qb/mMeTXG8Y3JaSGYYymjdy1MQBa6nkOiC8B4LT3ueCXaADdhL5k9w79BQRThrxDg4jYZbb+61XHHZKsOa+2XqA09VC9ri1zXMP52nR9Y0VKfGIvhGfOC1LnGcW7ALMy4XFtROZp2UtLR0URlqKqd++SKJg9046J9QABJIAJUKqvCNx+1WK+193tF+slXZTSGstNbRt8cbFUzCGKVjWPc2RheTssc4+g4a3oELH+MRfCM+cE8Yi+EZ84LQVo432Srqb/T3ihueJVNloBdamK+wsjJozzjt2GN7wW7Y4EbDgRogFQ+2cdLjmPFzALXb7RfsfsN1pLjUyi9W+OFtwYyOJ0L4ztz2gbcdHkOnt2NEILXte1421wcPzHa+lhsY/wA0l/3/APoFmUBERAREQFX3jlhN2zTFLa+wtgmvVku9He6SkqpOziqn08gf2Ln6PLzDYB10Ov0qwSx/kGh+BPz3e1BWXNrfnPFPFYJ34WMcu2P3e33u3UNfdIJvKEkEhdJE50Rc2MFvRriTskbDdbUP4jcNM84rxZtkM+MeQq2psdLY7ZZJa+CWecNrG1Es0j2v7No6aaOcnQcTokBXK8g0PwJ+e72p5BofgT893tQaByPA7teuNTruyAMssuH1lndWl7fQqJKmJzW8m+Y+i1x3rXTW9lQF+E53efBdqeH1XiTqG92qgoLbSvFwp5Irh2MkYdJGQ8cg5Yg7UnKfS1roreeQaH4E/Pd7U8g0PwJ+efagrVX8PMgnrOPL2W/mZk9JFFaT20f+UuFsEBHuvQ++Dl9Pl9/u6rF41iea8OcpoLtQ4v5ebX4nbLRURsuEMHiNXTdpvtS53pRntfdR85HKdNOwt34tlVhq+IN64ePZdai/2Khpq2atuELWMrIpuYCSN0Ya06LeU6a0b2ADp2p15BofgT893tQUUsHg837H7Vw+u174e27OpKDHTY7njlZPTGWkkFQ+aOeF8juyd/4jmuHMDojW+oVk+GWPUuN4hS09NitDhjpXOnms9udG6OF5OurmNDXOLQ3ZA7+mzra2x5BofgT893tTyDQ/An57vagyCIiAtJeEZxnumIeS8EwWKO5cT8o3DbKY9WUMPUSVs3fysYA4jY6kHoQ1wUq458ZrXwQwiS9VkMlxuVRI2jtNnp+s9xq39I4WAbPU95AOgD0J0DFfB04MXPEDdc7zqWO48T8o1Nc6hvpMoIehjooe/TGANB0epaOpDWlBLuBvCGi4JcPaTHKWrnudW6R9ZcbnUuJkrayQ7lmdsnWz3D1ADZJ2TP0RAREQEREBfMnuHfoK+lwRsEHuQVq8IvhlW8R8dsEtvtlDf6mxXeK6Oslyc1sFxiDHxyQlzgWtcWyEtc4aBA2oTeuEs964VZJS2DhPbsEvNXWW4RUlLPSdtUwxVkE0jpHREMaGhryG85J175AVvPIND8Cfnu9qeQaH4E/Pd7UFWeM3Bm+cTMvyttKxlLb7phXkiCvkkbyCsFWZmsc0Hn5dcuzy60T3nou610ufZnxX4e3y/YMcZpLFSXGGtm8p01QwyzRxNb2bWOLuQmM6JG+vUDvO7uFdkmkx+sN2ymhzSo8oVAZX29jI2RR8/owERkjmjHoknqfWpl5BofgT893tQebGP80l/wB//oFmV0UtHDRMLYW8jSdkbJXegIiICIiAiIgIiICIiCGcTqTNqi32h+CVdspa+K6U0lfHdGEsqKIO+/RtcASxxB2HAE9CBonaxt48IjhvY81s+I1OYW6TJbtUClpbbRvNTL2h5S1snZBwh5g9pBkLQ7Z1vR1BPDPoeMNdwxLOElRDE8NmF3ggYDcZ4HM5QymLgQDpzyeXUmwzkcCCHflf4NrZrV4SnDaKeJ9PPHk9BDJFI0tcxxqGNIIPceukH7oIiICwuaZlZ+HuK3PI7/Wx26z26Ez1FRJ3NaPUB3lxOgGjqSQB1Ky8srIInySPbHGwFznvOg0DvJPqCqtb45PDR4ksudQx33EMUrT4lA8EMyW4RnRmcP61PGdgDuce/e3BgZbgdhd441Z1Hxwz2jkpI+zdHhmO1HdbKN3/AJqRvd28o0d+oEf7IZZZcAAAADQHqC5QEREBERAREQEREBR3LuI+JcP/ABTzoyiy4343z+LeV7hDS9tycvPydo4c3LzN3ru5h74UiVUf6RnghJxT4J+cFvifNe8RdJXRsafd0rg0VLde+Axkm/eiIHegk3ArjnwIsuK19NjWX2bHaOS7Vcr6O+XmCKeSd0m3yta+UkxvPVpHQjuViF+P/wDR78DPuucb6e73CnEuPYsGXGpD27ZLPs+LxH/iBeQehETge9fsAgIiICIiAiIgIiICIiAondshudbdKq32R9JTiic2OprKuJ0wEha1/ZsY17TsMc0lxOhzNADuupYoDjxJu+U7O9XZ2voYV2ZPTE51Uxe0e8LD75sx+PrT+55P5hamz/wYKHiLxEx7Oa+rttFlNlrqevjuFutb4nVLoXtexs47ciQba0b0HaGg4BbxRdWfwj0jot2H5sx+PrT+55P5hObMfj60/ueT+YXqkvlvivUFofWwNuk8D6qOjMg7V8THNa6QN7+UF7QT3bcF57flVruuQXeyUtSZbnaWwurIOye3shK0uj9IgNdsNPuSda66TP4R6R0LojxS4d5NxYwquxe4ZjHa7bXgMqn2q2mKWaLfpRFxmdpju52tEjpvRIOaxrHb9h9gt9ks1yslutVBC2npqWGzSBsbGjQA/wAp/wAT1J6nqpUiZ/CPSOhd5rTkNyorpS2+9vpKgVrnR01ZSROhBkDXP7N7HPcdljXEOB0eUghvTcsUByEkXfFtHW7s3f0Myny5copiM2qItePdJERFxoIiICxmQ5Hb8Wtrq65VAggDgxo1t0jz3Na0dXOOj0HvE9wKyarXlGUyZvfpro6QvoWOdHb49+iyHu59f6z9cxPvFo9S9Ts/IpyzEmJm1Ma+n3XilV2433urkPke2Ulvg/qvuXNNIf0sjc0N/Y9yxh4t5nvpVWgf/XyfbKLIvtKez8loi0Ycfn8sc6Uo+61mf5XZ/wB3SfbL5m4q5hURPilqLNJG9pa5j7a8hwPQgjtuoUZRZ+Byb/XHoZ0sPwYs9TwEx2tsuJm2wUdZWyV0rqiifJIXu0A3m7Uei1oDWj1AdSSSTsD7rWZ/ldn/AHdJ9sousdW5Fb7fe7baKio7O4XJsr6WHkce0EQaZOoGhoOb3kb302pOR5LGvDj0hc6U5+61mf5XZ/3dJ9su+m4x5dTvDpm2esjHfGKaWFx/4+0cB80qIIk5Dks6Jw49EzpbywvilbstqG0M0L7XdSCW0szg5swA2TE8e60OuiA7oTrQ2poqryR84aQ98cjHB7JY3cr43A7Dmn1EHqCt+8M8tkzDF46ipLTcaaQ0lZyjQMrQDzAeoOa5r9erm0vlu0+zqcmiMXC+XZs/4y1pWiIvnkEREBERAUAx78L5V+tnfwYVP1AMe/C+VfrZ38GFd2Taq/p7wsapaE8IW6Xe/wCTZHR4jV5LFdcYsba6tnoshNrt9EXCV8TjG2N5qZXCNxLHDk5WNG2klfViv1644ZritiuuR3XH7b5jUGSTQ2GrdQz19VUuLXuMrNPEcfL7lpA5njexoLb2W8FcLzq/C83yxsrq8wtppXdvLHHURNJLY542PDJmgk6EjXAbK8d28H/Ar1ZrDa6qxONNYYfF7ZJDW1EVRSxa12bZ2SCTk0AOUuI0ANdFc2bo1pduG1I7wosLpKi+5HMabEKp4qTeqiKWZ0NXSgc5jc0ODg4l7dafoFwOgo7nWW5Fh2T8X7da8iulPDU3rHaKGsq6x9QLRHXP5aiSASEtiA5zygABp5dDoFvO8cCcHv1ssFBV2QiCwsdHbXU9ZPBLTscAHNEkb2vLXaGwSQdDe1lLhwuxa7S5PJXWeGsOSxQw3ZlQ572VTYmlkYLSdN5QehaAd6PeAUzZFbOMl4v3Bt3EDGrHl2QV1I7B5L9DPcrlJU1dvqo6pkIdHO487WyNefRJ1uM60NhbOxyluOB+EBaLBHkV6vNqveN1VdUw3iudU8tVBPA0Sx83SLmbM8FjA1ndpo0pTQ+D1w/t2PX6yRWEvob7C2nuTqitqJp6iJvuWGd8hlDR10A4AbOlLZsQtFRlNDkclJzXmipJaGnqe0eOSGRzHPZy75TsxsOyCRroRspFMjryH8L4r+tm/wAGZT9QDIfwviv62b/BmU/Uyn5aPp7ys6oERFwoIiIMXlUksWMXh8G+3bRzGPXfzch1/iqyWwNbbaQM9wImAdNdNBWuc0PaWuALSNEH1qsd2x2XDrxU2SUEMpzule7/AEtOT97cD6yB6J/O0+ohfWdhYlMd5hzr0STqeZFhMip8knfB5BuFromAHtRcaGSpLj01y8k0evX37/YsR5P4ha/D2M7/AFJUfza+omuYm2bM+nVgwvHXIrxZ7Rj1vs0hp573d4bdJUCp8WLWOY93K2Xkf2bnlgaHBpI2dddEQbJqDPcKwPJpqq6T2+ifLbhQubepLhV00prI2ykTSRMPI5rgOV3MO/1OIW1n4hccottba82fZb7a52t5aejoJaYtcDvmLnTvOx00W6IPrXNLwmxWjsNZZo7a91BWTRT1DZauaR8r43NdGTI55f0LG9N66a7lxYmDiYtVVUTa8aNOrRbyifrrVrHM8ku/CK65nT2u53G6QxYw27QMutS+qMFT27oi9pfshuiHFnd6PQBe2nw/zW4vcOJHZBdsgkqqK5OknuVYZ2OcIoSXxg9GB3N3N6aA6LbFZiNnuF4qLpU0LKisqKE22V0hc5slMXFxjLCeUgknrrfXW9KNWzgzjeLTxXDHLfHQXikikioairnqKmKAPABb2ZlHodB6II16tKTk9edeNMXiY06rTfmJ4ihht/EP1X7Gf3JUfza7aWhzxtVCam945JTh4MjIrPUMe5u+oa41RAOu4kH9BXZnzuzy6oly2TwEc/xrJ29ey7SncOnTnLHA/wCAYtZzTMgidJI7lY0bJW9OE2LT4xi3NWRmK4XCU1lRG7vjJa1rGH87WNaD/tcy8rtjEpoyWaJ11Wt9puzjzTVERfBAiIgIiIChlztVxsV3rq230D7tR18jZpaeCRjJoZQxrCW9o5rXMLWA62CCD7rm9GZotuHiThTeNN1ibID5bvPyLvf01D/Mp5bvPyLvf01D/MqfIunxUbkc+q3jYgPlu8/Iu9/TUP8AMp5bvPyLvf01D/MqfInio3I59S8bEB8t3n5F3v6ah/mU8t3n5F3v6ah/mVPkTxUbkc+peNiGWy1XG+3ahrbhQPtNHQSGeKnnkY+aaUscwF3Zuc1rAHk62SSR7nl9KZoi5sTEnFm86LJM3ERFqQREQFgsuw635lb209a1zJYnc8FTEdSQu1rYPrB9YOwf7lnUWdFdWHVFdE2mBoK7cJ8rtLyKanp77CPcyU0rYJT+mOQho/Y8/sWMOEZeCR5p15/RU0n26sgi96ntzKaYtNNM/afaYXRsVu8ycv8AklX/AFmk+3TzJy/5JV/1mk+3VkUWf87lG5Tz6mjYrd5k5f8AJKv+s0n26eZOX/JKv+s0n26siifzuUblPPqaNit3mTl/ySr/AKzSfbrvpuHmY1cgYMdfSb/0lZWQNYP09m97v7gVYpFJ7dyif8KefU0bGucI4Rx2OshuV5qI7jcInc8MMTSIIHe+N9XuHqcda9QB6rYyIvEx8oxMprz8WbygiIucf//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(get_state_update_bot().get_graph().draw_mermaid_png()))#state_update_bot\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='How do I make myself happy without the people who made me happy? Now that they’re gone, I feel sad. It’s been two months now but I seem to be unable to stay okay and independent.'), AIMessage(content=\"I'm sorry to hear that you're going through a tough time. It's completely normal to feel sad and miss the people who made you happy. Here are some tips that might help you make yourself happy and feel more independent:\\n\\n1. **Practice Self-Care**: Take care of yourself by getting enough sleep, eating well, exercising, and practicing relaxation techniques like meditation or deep breathing.\\n\\n2. **Engage in Activities You Enjoy**: Focus on activities that bring you joy and fulfillment, whether it's a hobby, exercise, reading, or spending time in nature.\\n\\n3. **Connect with Supportive People**: Reach out to friends, family members, or a therapist who can provide emotional support and understanding during this time.\\n\\n4. **Set Goals and Prioritize Self-Improvement**: Setting goals and working towards them can give you a sense of purpose and accomplishment. Focus on personal growth and self-improvement.\\n\\n5. **Practice Gratitude**: Take time to appreciate the good things in your life, no matter how small. Keeping a gratitude journal can help shift your focus to the positive aspects of your life.\\n\\n6. **Seek Professional Help**: If you're struggling to cope with your emotions and find it difficult to feel happy on your own, consider seeking help from a therapist or counselor.\\n\\nRemember, it's okay to feel sad and it's important to give yourself time to heal. Be patient with yourself and take small steps towards finding happiness and independence.\", response_metadata={'token_usage': {'completion_tokens': 294, 'prompt_tokens': 286, 'total_tokens': 580}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8a38e570-0dfa-4f5e-9b57-72e56df81d33-0', usage_metadata={'input_tokens': 286, 'output_tokens': 294, 'total_tokens': 580})]}\n"
     ]
    }
   ],
   "source": [
    "# This code block imports the HumanMessage class from the langchain_core.messages module.\n",
    "# It creates a dictionary named inputs containing a list of messages, which in this case consists of a single HumanMessage with the content \"What is the fundamental mechanism behind CRISPR-Cas9 gene editing, and how does it differ from other gene editing techniques?\".\n",
    "# It invokes the compiled workflow app using the invoke() method, passing the inputs dictionary as an argument.\n",
    "# The workflow processes the input message, executes the defined nodes and edges, and returns the generated response.\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\" : [HumanMessage(content=mental_health_counseling_data['test'][2][\"Context\"])]}\n",
    "\n",
    "print(app.invoke(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that you're going through a tough time. It's completely normal to feel sad and miss the people who made you happy. Here are some tips that may help you make yourself happy and feel more independent:\n",
      "\n",
      "1. **Practice Self-Care**: Take care of yourself by getting enough sleep, eating well, exercising, and engaging in activities that bring you joy.\n",
      "\n",
      "2. **Set Goals**: Setting small, achievable goals for yourself can give you a sense of purpose and accomplishment.\n",
      "\n",
      "3. **Stay Connected**: While the people who made you happy may be gone, try to stay connected with friends and family who support you and make you feel good.\n",
      "\n",
      "4. **Find New Hobbies**: Explore new hobbies or activities that interest you. This can help you discover new passions and meet new people.\n",
      "\n",
      "5. **Practice Gratitude**: Take time each day to reflect on the things you are grateful for. This can help shift your focus to the positive aspects of your life.\n",
      "\n",
      "6. **Seek Professional Help**: If you're struggling to cope with your feelings, consider talking to a therapist or counselor who can provide support and guidance.\n",
      "\n",
      "Remember, it's okay to feel sad and it's important to give yourself time to heal. Take things one day at a time and be kind to yourself during this process.\n"
     ]
    }
   ],
   "source": [
    "print(output['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It sounds like you have been feeling pretty down, since the loss of a relationship, and you're wondering how to be happy by yourself. Intimacy is a very natural human desire and at the same time learning to enjoy ourselves, even when we are alone, can strengthen our ability to lead a satisfying life in and out of relationship. Working with a therapist, you may be able to gain insight into how you show up in your relationships with yourself and others and discover more fulfilling ways to do so.\""
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mental_health_counseling_data['test'][2]['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How do I make myself happy without the people who made me happy? Now that they’re gone, I feel sad. It’s been two months now but I seem to be unable to stay okay and independent.')]}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the information gathered, here is a brief response to your question:\\n\\nResponse: To make yourself happy without relying on others, it is important to differentiate between emotional dependence and emotional support, take charge of your own life, embrace change, and cultivate supportive relationships.\\n\\nFollow-up question: Can you share more about the activities or hobbies that used to bring you joy when you were with the people who made you happy?\\n\\nNow, let's proceed with providing a tailored diet plan, physical activity schedule, and an action plan for further support based on the identified issue.\\n### Tailored Diet Plan:\\n- Focus on consuming a balanced diet rich in fruits, vegetables, whole grains, lean proteins, and healthy fats.\\n- Incorporate mood-boosting foods such as fatty fish, nuts, seeds, and dark chocolate.\\n- Stay hydrated by drinking plenty of water throughout the day.\\n\\n### Physical Activity Schedule:\\n- Engage in regular physical exercise such as walking, jogging, yoga, or dancing to boost your mood and overall well-being.\\n- Aim for at least 30 minutes of moderate-intensity exercise most days of the week.\\n- Include activities that you enjoy to make exercise a fun and rewarding experience.\\n\\n### Action Plan for Further Support:\\n1. Consider seeking therapy or counseling to explore and address the underlying emotions related to your current situation.\\n2. Practice mindfulness and relaxation techniques to manage stress and improve emotional resilience.\\n3. Connect with supportive friends, family members, or support groups to share your feelings and receive encouragement.\\n4. Explore self-care activities that promote self-love and self-compassion, such as journaling, meditation, or creative expression.\\n\\nIf you feel that you would benefit from more personalized support, please consider scheduling an in-person meeting with a mental health professional for tailored guidance and assistance.\\n\\n### Relevant Spiritual Music:\\nI will now find a relevant spiritual music recommendation to enhance your emotional well-being.\""
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Define the function to convert inputs\n",
    "# def convert_inputs(input_object):\n",
    "#     system_prompt = f\"\"\"You are a qualified psychologist providing mental health advice. Your task is to:\n",
    "\n",
    "#     1. Analyze the user's question to identify potential mental health issues.\n",
    "#     2. Provide a brief, one-sentence response addressing the main concern.\n",
    "#     3. Ask a follow-up question to gather more information about the user's specific situation.\n",
    "#     4. Based on the identified issue, provide:\n",
    "#        a) A tailored diet plan in structured format\n",
    "#        b) A physical activity schedule in structured format\n",
    "#        c) An action plan or resources for further support\n",
    "#     5. If the situation requires more in-depth assistance, provide a link to schedule an in-person meeting.\n",
    "\n",
    "#     Use the following tools in this order:\n",
    "#     1. RAG (Retrieval-Augmented Generation) to access relevant mental health information.\n",
    "#     2. InternetSearch to find up-to-date resources and recommendations.\n",
    "#     3. Find a relevant spiritual music\n",
    "\n",
    "#     You may make multiple calls to these tools as needed to provide comprehensive advice.\n",
    "\n",
    "#     Present your final response in a clear, structured format, including a chart of recommended actions if appropriate.\n",
    "\n",
    "#     User's question: {input_object['question']}\n",
    "\n",
    "#     Response:\n",
    "#     \"\"\"\n",
    "#     return {\"messages\": [HumanMessage(content=system_prompt)]}\n",
    "\n",
    "# # Define the function to parse the output\n",
    "# def parse_output(input_state):\n",
    "#     return input_state[\"messages\"][-1].content\n",
    "\n",
    "# bot=get_state_update_bot()\n",
    "# # Create the agent chain\n",
    "# agent_chain = convert_inputs | bot | parse_output\n",
    "\n",
    "# # Run the agent chain with the input\n",
    "# await agent_chain.ainvoke({\"question\": mental_health_counseling_data['test'][2]['Context']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Observation: The search results provide tips and insights on finding happiness and independence after experiencing loss. Some key points include believing in the possibility of happiness, setting new goals, and exploring unconventional ways to discover joy and healing.\\n\\nResponse:\\nBased on the information gathered, here are some practical steps you can take to make yourself happy without relying on the people who made you happy:\\n\\n1. Believe in Your Ability to Find Happiness: Start by believing that you can be happy again, even in a different way than before. Trust in your resilience and strength to navigate this challenging time.\\n\\n2. Set New Goals and Intentions: Define new goals and aspirations for yourself that align with your values and interests. Having a sense of purpose can contribute to your overall happiness and fulfillment.\\n\\n3. Explore Unconventional Ways to Discover Joy: Consider trying new activities, hobbies, or practices that bring you joy and fulfillment. Sometimes, stepping out of your comfort zone can lead to unexpected sources of happiness.\\n\\n4. Practice Self-Compassion and Self-Care: Be kind to yourself during this period of transition. Prioritize self-care activities that nurture your well-being, such as mindfulness, exercise, or spending time in nature.\\n\\n5. Seek Support from Trusted Sources: While it's natural to feel sad after losing significant relationships, reaching out to family members, friends, or a counselor can provide additional support and guidance during this time.\\n\\n6. Reflect on Your Values and Emotions: Take time to reflect on your values, emotions, and needs. Understanding yourself better can help you cultivate a sense of independence and self-fulfillment.\\n\\nRemember, finding happiness and independence is a journey that takes time and self-exploration. It's okay to seek help and support along the way. If you find it challenging to cope with these emotions on your own, consider reaching out to a mental health professional for further assistance.\\n\\nIf you have any more questions or need additional guidance, feel free to ask. You are not alone in this journey towards rediscovering happiness and independence.\""
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_inputs(input_object):\n",
    "    system_prompt = f\"\"\"You are a qualified psychologist providing mental health advice. Be empathetic in your responses. \n",
    "\n",
    "\n",
    "Use a compassionate yet direct tone, avoiding excessive reassurance or filler phrases.\n",
    "Include relevant concepts or theories that might help explain the situation (e.g., codependency, time management, intimacy issues).\n",
    "When applicable, mention potential external factors that could be influencing the situation (e.g., pregnancy affecting sex drive, seasonal changes affecting mood).\n",
    "Encourage the user to seek additional support from trusted sources (e.g., family members, school counselors) if professional help is not immediately accessible.\n",
    "Offer alternative perspectives to help reframe the issue.\n",
    "Provide concise responses for simpler questions, but offer more detailed explanations for complex issues.\n",
    "Use examples or analogies to illustrate points when helpful.\n",
    "End with a brief statement of encouragement or invitation for further questions if needed.\n",
    "\n",
    "\n",
    "You will operate in a loop of Thought, Action, PAUSE, and Observation. At the end of the loop, you will provide an Answer.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Thought: Describe your thoughts about the user's question.\n",
    "Action: Choose one of the available actions to gather information or provide insights.\n",
    "PAUSE: Pause to allow the action to complete.\n",
    "Observation: Review the results of the action.\n",
    "\n",
    "Available Actions:\n",
    "\n",
    "Use the following tools in this order:\n",
    "\n",
    "    1. rag_tool: RAG (Retrieval-Augmented Generation) to access relevant mental health information.\n",
    "    2. DuckDuckGoSearchRun: Perform an online search: InternetSearch to find up-to-date resources and recommendations.\n",
    "    3. ArxivQueryRun: Find relevant research or content.\n",
    "    3. PubMedQuerRun: Find a specific coping strategies or management techniques by doing research paper\n",
    "\n",
    "    You may make multiple calls to these tools as needed to provide comprehensive advice.\n",
    "\n",
    "    Present your final response in a clear, structured format, including a chart of recommended actions if appropriate.\n",
    "\n",
    "    User's question: {input_object['question']}\n",
    "\n",
    "    Response: Your task is When responding to users' personal issues or concerns:\n",
    "\n",
    "1. With a brief empathetic acknowledgment of the user's situation, continue\n",
    "2. Provide practical, actionable advice that often includes and\n",
    "\n",
    "3. Suggesting professional help (e.g., therapists, counselors) when appropriate and\n",
    "4. Encouraging open communication and dialogue with involved parties and \n",
    "5. Recommending self-reflection or exploration of emotions and values and\n",
    "6. Offering specific coping strategies or management techniques and\n",
    "\"\"\"\n",
    "    return {\"messages\": [HumanMessage(content=system_prompt)]}\n",
    "\n",
    "# Define the function to parse the output\n",
    "def parse_output(input_state):\n",
    "    return input_state[\"messages\"][-1].content\n",
    "\n",
    "bot=get_state_update_bot()\n",
    "# Create the agent chain\n",
    "agent_chain = convert_inputs | bot | parse_output\n",
    "\n",
    "# Run the agent chain with the input\n",
    "await agent_chain.ainvoke({\"question\": mental_health_counseling_data['test'][2]['Context']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I make myself happy without the people who made me happy? Now that they’re gone, I feel sad. It’s been two months now but I seem to be unable to stay okay and independent.'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=agent_chain.invoke({\"question\": mental_health_counseling_data['test'][2]['Context']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The search results suggest several strategies for finding happiness independently after losing people who made you happy. These include:\n",
      "\n",
      "1. Find joy in creativity: Engage in creative activities like painting, writing, or playing an instrument to express emotions and find healing.\n",
      "2. Support others: Helping people can provide a sense of purpose and contribute to your happiness.\n",
      "3. Practice mindfulness: Stay present in the moment and focus on self-care to improve emotional well-being.\n",
      "4. Lean on your support system: Seek support from family, friends, or a professional counselor to talk about your feelings and experiences.\n",
      "\n",
      "Based on these suggestions, here are some actionable steps you can take:\n",
      "\n",
      "1. Engage in creative activities: Dedicate time to explore your creative side through art, writing, or music.\n",
      "2. Volunteer or help others: Find opportunities to support people in need to cultivate a sense of purpose.\n",
      "3. Practice mindfulness: Incorporate mindfulness practices like meditation or deep breathing exercises into your daily routine.\n",
      "4. Seek support: Reach out to trusted individuals or a counselor to talk about your feelings and seek guidance.\n",
      "\n",
      "Remember, it's okay to grieve and take time for self-care during this process. Celebrate the memories of those who brought happiness into your life while focusing on your own well-being and growth.\n",
      "\n",
      "End with a brief statement of encouragement: You are capable of finding happiness within yourself, even after experiencing loss. Take small steps each day towards self-discovery and healing. If you need further guidance or support, feel free to ask more questions.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mental_health_counseling_data['test'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Evaluation DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I asked gpt40 to create must mention for the first 10 questions.\n",
    "must_have_list=[['Time management', 'Focus', 'Calendar'], \n",
    "['Trust', 'Communication', 'Therapy'],\n",
    "['Happiness', 'Independence', 'Self-discovery'],\n",
    "['Relationships', 'emotions', 'Support'],\n",
    "['Rejection', 'Medical exam', 'intimacy'],\n",
    "['Depression', 'Affordable counselin', 'Support'],\n",
    "['Sadness', 'winter', 'reflection'],\n",
    "['Codependency', 'Emotions', 'counseling'],\n",
    "['Anxiety', 'Professional help', 'support'],\n",
    "['Pregnancy', 'Intimacy', 'therapy']]\n",
    "\n",
    "\n",
    "questions=[]\n",
    "answers=[]\n",
    "for i in range(10):\n",
    "    \n",
    "    questions.append(mental_health_counseling_data['test'][i]['Context'])\n",
    "    answers.append({'must mention': must_have_list[i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE3 - LangGraphDemo -{uuid4().hex[0:8]}\"# {'9dc7f3da'}\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9d2524d4'"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid4().hex[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding our dataset to LangSmit Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = f\"Retrieval Augmented Generation - Evaluation Dataset -{uuid4().hex[0:8]}\"#{'5a4498e2'}\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions about the Mental Health concerns to Evaluate RAG over the solutions provided by professional Mental Health Advisor.\"\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\" : q} for q in questions],\n",
    "    outputs=answers,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Evaluator\n",
    " a fairly naive exact-match process to determine if our response contains specific strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "\n",
    "@run_evaluator\n",
    "def must_mention(run, example) -> EvaluationResult:\n",
    "    prediction = run.outputs.get(\"output\") or \"\"\n",
    "    required = example.outputs.get(\"must_mention\") or []\n",
    "    score = all(phrase in prediction for phrase in required)\n",
    "    \n",
    "    return EvaluationResult(key=\"must_mention\", score=score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our custom evaluator - let's initialize our `RunEvalConfig` with it, and a few others:\n",
    "\n",
    "- `\"criteria\"` includes the default criteria which, in this case, means \"helpfulness\"\n",
    "- `\"cot_qa\"` includes a criteria that bases whether or not the answer is correct by utilizing a Chain of Thought prompt and the provided context to determine if the response is correct or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'RAG Pipeline - Evaluation -6cea40d7' at:\n",
      "https://smith.langchain.com/o/011bb40b-887f-5e52-ae2b-cac14745aa21/datasets/f28ae565-a4b8-4f30-9d7e-059c6e8a6c0d/compare?selectedSessions=b4ffd6aa-1f2b-4575-923a-a1ae4f36baef\n",
      "\n",
      "View all tests for Dataset Retrieval Augmented Generation - Evaluation Dataset -9a300fe2 at:\n",
      "https://smith.langchain.com/o/011bb40b-887f-5e52-ae2b-cac14745aa21/datasets/f28ae565-a4b8-4f30-9d7e-059c6e8a6c0d\n",
      "[>                                                 ] 0/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example c8a21fcd-07d6-47a7-878b-cc9adebf0f3d with inputs {'question': \"I'm feeling rejected and frustrated. This is not new. The first month we were together, sex was about every day. Then it slowed down to once a month right away. I love my husband, but I am struggling with this.\"}\n",
      "Error Type: TypeError, Message: PubmedQueryRun._run() got an unexpected keyword argument '__arg1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---->                                             ] 1/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example f9b3e454-464d-4af8-943e-e95311c348ef with inputs {'question': \"I'm depressed. I have been for years. I hide it from everyone because I'm scared of the reactions I'll get. Last time I tried telling my parents, it was a huge argument about me being too young to be depressed (I’m a legal adult), calling me ungrateful, and telling me that if I can't handle things now, it's only going to get worse in the future (which is turning out to be true). It's exhausting pretending to be okay, and I don't know how much longer I can try. I'm just really tired, and sadly, I can't afford the help I need on my own.\"}\n",
      "Error Type: TypeError, Message: PubmedQueryRun._run() got an unexpected keyword argument '__arg1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[---------------------------------->               ] 7/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chain failed for example 326aea93-100c-47ec-aaa9-3c47439298ee with inputs {'question': 'My wife and I have a great relationship except for our sex lives. We are pretty transparent and honest, and basically, she feels bad because she never wants to have sex. She doesn\\'t have the desire. She\\'s also never orgasmed. She feels like a terrible wife and fears I\\'ll cheat on her. She doesn\\'t know why. Last time we had sex, she cried and felt bad and didn\\'t know why she cried. However, she also told me that the last time we had sex, she felt me in her, but it just felt \"ehh\" and wanted to stop. That makes me feel really awful. We rarely have foreplay. Everything I try tickles her, so she makes me stop. We are both frustrated but very much in love. She and I are in our early 20s. We’re married and we have a baby on the way.'}\n",
      "Error Type: TypeError, Message: PubmedQueryRun._run() got an unexpected keyword argument '__arg1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 10/10"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.COT Contextual Accuracy</th>\n",
       "      <th>feedback.must_mention</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>PubmedQueryRun._run() got an unexpected keywor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daf0e9ea-8773-4a89-869d-ab2731a213b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.940474</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.769421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.420039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.360025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.478747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.298773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.225447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.helpfulness  feedback.COT Contextual Accuracy  \\\n",
       "count                    7.0                          7.000000   \n",
       "unique                   NaN                               NaN   \n",
       "top                      NaN                               NaN   \n",
       "freq                     NaN                               NaN   \n",
       "mean                     1.0                          0.857143   \n",
       "std                      0.0                          0.377964   \n",
       "min                      1.0                          0.000000   \n",
       "25%                      1.0                          1.000000   \n",
       "50%                      1.0                          1.000000   \n",
       "75%                      1.0                          1.000000   \n",
       "max                      1.0                          1.000000   \n",
       "\n",
       "       feedback.must_mention  \\\n",
       "count                      7   \n",
       "unique                     1   \n",
       "top                     True   \n",
       "freq                       7   \n",
       "mean                     NaN   \n",
       "std                      NaN   \n",
       "min                      NaN   \n",
       "25%                      NaN   \n",
       "50%                      NaN   \n",
       "75%                      NaN   \n",
       "max                      NaN   \n",
       "\n",
       "                                                    error  execution_time  \\\n",
       "count                                                   3       10.000000   \n",
       "unique                                                  3             NaN   \n",
       "top     PubmedQueryRun._run() got an unexpected keywor...             NaN   \n",
       "freq                                                    1             NaN   \n",
       "mean                                                  NaN        6.940474   \n",
       "std                                                   NaN        2.769421   \n",
       "min                                                   NaN        2.420039   \n",
       "25%                                                   NaN        5.360025   \n",
       "50%                                                   NaN        7.478747   \n",
       "75%                                                   NaN        8.298773   \n",
       "max                                                   NaN       12.225447   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     10  \n",
       "unique                                    10  \n",
       "top     daf0e9ea-8773-4a89-869d-ab2731a213b6  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'project_name': 'RAG Pipeline - Evaluation -6cea40d7',\n",
       " 'results': {'fcfee49a-e92e-4d28-b2e5-e255da47598c': {'input': {'question': 'I feel like my time is going too fast'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment=\"The criterion for this task is the helpfulness of the submission. \\n\\nThe submission provides an observation about the perception of time passing quickly, which is directly related to the input. It then provides an answer with actionable steps to address the feeling of time passing too quickly. These steps are clear, practical, and directly related to the observation. \\n\\nThe submission also encourages the user to prioritize self-care and balance in their daily life, and suggests seeking support from a mental health professional if the feeling persists. This shows a comprehensive approach to the issue, which is helpful for the user. \\n\\nThe submission also offers the user the opportunity to ask more questions or seek additional support, which is a helpful and appropriate response to the user's input. \\n\\nTherefore, the submission is helpful, insightful, and appropriate, meeting the criterion. \\n\\nY\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('29c45340-8d80-43d8-8b4c-43ab479dfe21'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=1, value='CORRECT', comment=\"The student's answer is addressing the question in a comprehensive manner. The student has provided a detailed response on how to manage the feeling of time passing too quickly, which is relevant to the context of 'Time management', 'Focus', and 'Calendar'. The student has also provided actionable steps and strategies to manage this feeling, which is a practical approach to the question. The student's answer does not conflict with the context provided and is factually accurate. \\nGRADE: CORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('ed74f25f-b9fd-4f48-a3ab-74e6b2e5a516'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('e54dc88f-705b-4948-9210-7038cdc54177'), target_run_id=None)],\n",
       "   'execution_time': 8.374029,\n",
       "   'run_id': 'daf0e9ea-8773-4a89-869d-ab2731a213b6',\n",
       "   'output': \"Observation: The perception of time passing quickly can be influenced by various factors such as engagement in activities, busyness, and psychological factors. Reflecting on daily routines, practicing mindfulness, and being present in the moment are suggested strategies to manage this feeling.\\n\\nAnswer: Based on the information retrieved, here are some actionable steps to address the feeling of time passing too quickly:\\n\\n1. Reflect on Daily Routines: Take time to analyze your daily activities and identify any patterns that may contribute to the perception of time passing quickly.\\n2. Practice Mindfulness: Engage in mindfulness techniques to stay present in the moment and appreciate the passage of time.\\n3. Savor Moments: Focus on savoring enjoyable moments and activities to create a sense of time well spent.\\n\\nRemember, it's essential to prioritize self-care and balance in your daily life to manage the feeling of time slipping away. If you continue to struggle with this perception, consider seeking support from a mental health professional for further guidance and coping strategies. Feel free to ask more questions or seek additional support if needed.\",\n",
       "   'reference': {'must mention': ['Time management', 'Focus', 'Calendar']}},\n",
       "  'fef8c3de-4bd0-40c9-97bd-ea8db28cc3e6': {'input': {'question': \"I’m trying to make marriage work after a split. Before our split, he lied a lot and broke every promise to me. I don't think he cheated. Last month, I asked what women work with him, so he told me. Yesterday, I found out about a girl that he said he forgot about. Should I be upset?\"},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment='The criterion for this task is helpfulness. The submission should be helpful, insightful, and appropriate.\\n\\n1. Helpfulness: The submission provides a detailed response to the input, offering strategies to navigate trust issues in a relationship after betrayal. It suggests acknowledging the lies and broken promises, taking responsibility for the behavior, apologizing sincerely, being transparent and honest going forward, and giving each other time to heal. This advice is helpful for someone trying to rebuild trust in a relationship.\\n\\n2. Insightfulness: The submission is insightful as it recognizes the complexity of the situation and provides a thoughtful response. It acknowledges the difficulty of rebuilding trust after a history of lies and broken promises and suggests seeking professional help to facilitate the process.\\n\\n3. Appropriateness: The submission is appropriate as it addresses the concerns raised in the input. It does not make any assumptions or judgments about the situation, instead offering advice on how to navigate the situation.\\n\\nBased on this analysis, the submission meets the criterion of being helpful, insightful, and appropriate.\\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('006218b6-ae05-458c-9b53-2dce43cf5acd'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=0, value='INCORRECT', comment=\"The student's answer does not directly answer the question asked. The question is asking for advice on whether the person should be upset about a specific situation, but the student's answer provides general advice on how to rebuild trust in a relationship. While the advice given is factually accurate and relevant to the context, it does not directly address the question asked. Therefore, the answer is incorrect.\\nGRADE: INCORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('28839849-067d-4162-b66e-59adf64e5ed2'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('54d36b41-b777-4fce-852f-58b8437bcf18'), target_run_id=None)],\n",
       "   'execution_time': 7.393401,\n",
       "   'run_id': 'd190a1a2-d48e-436a-9233-b480bfa33c4f',\n",
       "   'output': \"### Thought\\nRebuilding trust in a relationship after a history of lies and broken promises is a challenging but possible journey that requires commitment from both partners.\\n\\n### Action\\nBased on the search results, here are some strategies to navigate trust issues in a relationship after betrayal:\\n1. Acknowledge the lies and broken promises.\\n2. Take responsibility for the behavior.\\n3. Apologize sincerely.\\n4. Be transparent and honest going forward.\\n5. Give each other time to heal.\\n\\n### PAUSE\\n\\n### Observation\\nThe process of rebuilding trust involves acknowledging the breach, taking responsibility, and fostering open communication and personal growth.\\n\\n### Answer\\nTo navigate trust issues in your relationship after a history of lies and broken promises, it's essential to communicate openly, take responsibility for past actions, and work together to rebuild trust. Consider seeking professional help to facilitate this process and prioritize honest and transparent communication moving forward.\",\n",
       "   'reference': {'must mention': ['Trust', 'Communication', 'Therapy']}},\n",
       "  '839c5286-5e01-4273-802d-03b52951595b': {'input': {'question': 'How do I make myself happy without the people who made me happy? Now that they’re gone, I feel sad. It’s been two months now but I seem to be unable to stay okay and independent.'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment='The criterion for this task is \"helpfulness\". \\n\\n1. The submission provides a detailed response to the user\\'s question, offering actionable steps to cope with their feelings of sadness and loss. This makes the submission helpful.\\n\\n2. The submission is insightful as it not only provides steps but also explains why these steps are important and how they can help the user. \\n\\n3. The tone of the submission is empathetic and supportive, which is appropriate given the user\\'s emotional state. \\n\\n4. The submission also encourages the user to seek additional support if needed, which is a helpful and appropriate suggestion.\\n\\nBased on these points, the submission meets the criterion of being helpful, insightful, and appropriate. \\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('f7ba7a2c-0469-4b93-b72a-9f0bac231a71'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=1, value='CORRECT', comment=\"The student's answer provides a comprehensive response to the question. The student suggests several strategies for coping with loss and finding happiness independently, which aligns with the context of 'Happiness', 'Independence', and 'Self-discovery'. The student's answer does not contradict any known facts and provides a thoughtful, empathetic response to the question. Therefore, the student's answer is factually accurate.\\nGRADE: CORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('4bd59a7f-1fab-4c72-83a1-7d48fe5a5b0d'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('41614871-4fe3-4d79-b6db-7fe5b74247c4'), target_run_id=None)],\n",
       "   'execution_time': 12.225447,\n",
       "   'run_id': '4222de42-2f50-4a64-8a89-31e5348288a3',\n",
       "   'output': \"Observation: The search results provide valuable insights on coping strategies for dealing with loss and finding happiness independently. Key points include giving oneself permission to grieve, embracing social support, practicing self-compassion, and prioritizing rest.\\n\\nBased on the information gathered, here are some tailored recommendations for the user:\\n\\n| Action Steps |\\n|--------------|\\n| 1. Give Yourself Permission to Grieve: Allow yourself to experience and express your emotions without judgment. It's okay to feel sad and take the time you need to process your loss. |\\n| 2. Embrace Social Support: Lean on trusted friends, family members, or support groups for emotional support and companionship during this challenging time. Connecting with others can help alleviate feelings of loneliness. |\\n| 3. Practice Self-Compassion: Be kind to yourself and treat yourself with the same understanding and care you would offer to a loved one in distress. Self-compassion can help you navigate through difficult emotions with gentleness. |\\n| 4. Prioritize Rest: Ensure you are taking care of your physical well-being by getting enough rest and sleep. Rest is essential for emotional regulation and overall mental health. |\\n\\nThese steps can assist you in navigating through the process of grief and finding happiness independently. Remember, it's okay to seek additional support from trusted individuals or professionals if needed.\\n\\nIf you have any further questions or need more guidance, feel free to ask. You are not alone in this journey towards healing and self-discovery.\",\n",
       "   'reference': {'must mention': ['Happiness',\n",
       "     'Independence',\n",
       "     'Self-discovery']}},\n",
       "  '6c74e766-a579-47c0-b852-6bd2b04f3f34': {'input': {'question': 'I have suffered many things at home and school. We never went to the doctor to diagnose depression or anything like that, but I always feel like a part of my heart is missing. I try to fill it in with objects or, in this case, a woman.'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment=\"The criterion for this task is the helpfulness of the submission. \\n\\n1. The submission acknowledges the user's feelings and validates their experience, which is a helpful response to someone sharing their struggles.\\n2. The submission encourages self-reflection, which can be insightful for the user to understand their feelings better.\\n3. The submission recommends seeking professional help, which is an appropriate and helpful suggestion for someone who might be dealing with depression.\\n4. The submission suggests developing healthier coping mechanisms, which is a helpful and insightful suggestion.\\n5. The submission offers empathy and understanding, which is helpful and appropriate in this context.\\n\\nBased on these points, the submission meets the criterion of being helpful, insightful, and appropriate.\\n\\nY\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('9124a97f-00be-44ea-a486-25fa0a50914e'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=1, value='CORRECT', comment=\"The student's answer is a structured response to the user's situation. It acknowledges the user's feelings, encourages self-reflection, recommends seeking professional help, suggests developing healthier coping mechanisms, and offers empathy and understanding. This response is in line with the context of 'Relationships', 'emotions', and 'Support'. Therefore, the student's answer is factually accurate and addresses the context appropriately.\\nGRADE: CORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('d4f74bd9-88b6-4ffe-b3d4-b00f48ed3f8a'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('588b50b0-2e3c-44d4-b690-04c18fdffbd8'), target_run_id=None)],\n",
       "   'execution_time': 7.564093,\n",
       "   'run_id': '71e25ce7-4595-4094-ac16-abcae0a7db79',\n",
       "   'output': \"Based on the RAG tool's insights, here is a structured response to the user's situation:\\n\\n| Action Steps |\\n|--------------|\\n| 1. Acknowledge the user's feelings and validate their experience. |\\n| 2. Encourage self-reflection to explore the underlying emotions causing the void. |\\n| 3. Recommend seeking professional help from a therapist or counselor for support. |\\n| 4. Suggest developing healthier coping mechanisms to address the root cause. |\\n| 5. Offer empathy and understanding throughout the process. |\\n\\nRemember, seeking help is a sign of strength, and you deserve support in navigating your emotional struggles. If you have any more questions or need further guidance, feel free to ask.\",\n",
       "   'reference': {'must mention': ['Relationships', 'emotions', 'Support']}},\n",
       "  'c8a21fcd-07d6-47a7-878b-cc9adebf0f3d': {'input': {'question': \"I'm feeling rejected and frustrated. This is not new. The first month we were together, sex was about every day. Then it slowed down to once a month right away. I love my husband, but I am struggling with this.\"},\n",
       "   'feedback': [],\n",
       "   'execution_time': 2.420039,\n",
       "   'run_id': 'd72bb48c-8e76-469f-8bd4-0f78afcca611',\n",
       "   'Error': TypeError(\"PubmedQueryRun._run() got an unexpected keyword argument '__arg1'\"),\n",
       "   'reference': {'must mention': ['Rejection', 'Medical exam', 'intimacy']}},\n",
       "  'f9b3e454-464d-4af8-943e-e95311c348ef': {'input': {'question': \"I'm depressed. I have been for years. I hide it from everyone because I'm scared of the reactions I'll get. Last time I tried telling my parents, it was a huge argument about me being too young to be depressed (I’m a legal adult), calling me ungrateful, and telling me that if I can't handle things now, it's only going to get worse in the future (which is turning out to be true). It's exhausting pretending to be okay, and I don't know how much longer I can try. I'm just really tired, and sadly, I can't afford the help I need on my own.\"},\n",
       "   'feedback': [],\n",
       "   'execution_time': 3.68039,\n",
       "   'run_id': '090a8e2a-5003-4dcb-8532-1a66c313eea9',\n",
       "   'Error': TypeError(\"PubmedQueryRun._run() got an unexpected keyword argument '__arg1'\"),\n",
       "   'reference': {'must mention': ['Depression',\n",
       "     'Affordable counselin',\n",
       "     'Support']}},\n",
       "  '3ccbeb8e-2916-497c-aab1-897cab4ba322': {'input': {'question': 'Every winter I find myself getting sad because of the weather. How can I fight this?'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment=\"The criterion for this task is helpfulness. The submission should be helpful, insightful, and appropriate.\\n\\nLooking at the submission, it starts by identifying the possible issue the user is facing, which is Seasonal Affective Disorder (SAD). This is insightful as it provides a potential explanation for the user's feelings of sadness during the winter.\\n\\nThe submission then provides a list of coping strategies for SAD. These strategies are helpful and appropriate as they are commonly recommended for dealing with SAD. They include getting regular exposure to natural light, maintaining a healthy diet and exercise routine, practicing relaxation techniques, and seeking professional help.\\n\\nThe submission ends by encouraging the user to incorporate these strategies into their daily routine and to seek professional help if needed. This is helpful as it provides the user with a clear action plan.\\n\\nTherefore, the submission meets the criterion of being helpful, insightful, and appropriate.\\n\\nY\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('6a4f9f3c-a400-4985-9733-ff0b8557e097'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=1, value='CORRECT', comment=\"The student's answer correctly identifies the potential issue as Seasonal Affective Disorder (SAD) based on the context provided. The student then provides a list of coping strategies that are commonly recommended for dealing with SAD, including exposure to natural light, maintaining a healthy lifestyle, practicing relaxation techniques, and seeking professional help. The student's answer is comprehensive and directly addresses the question, providing actionable advice for dealing with the issue. Therefore, the student's answer is factually accurate.\\nGRADE: CORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('dc2c6bfc-8798-4829-978e-7481d875e50c'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('acb0706c-8501-4974-888a-7176e1b009bb'), target_run_id=None)],\n",
       "   'execution_time': 6.209753,\n",
       "   'run_id': '9796fc92-38ff-4994-aa26-12c4b97581be',\n",
       "   'output': '**Thought:** It seems like you may be experiencing Seasonal Affective Disorder (SAD), a type of depression that occurs during specific seasons, often in the winter months due to reduced sunlight exposure.\\n\\n**Action:** I will provide you with some coping strategies for Seasonal Affective Disorder.\\n\\n**PAUSE**\\n**Observation:**\\nSeasonal Affective Disorder (SAD) coping strategies include:\\n1. Getting regular exposure to natural light\\n2. Maintaining a healthy diet and exercise routine\\n3. Practicing relaxation techniques\\n4. Seeking professional help such as therapy or medication\\n\\n**Answer:** To fight the sadness you experience in winter, try incorporating these coping strategies into your daily routine. Remember, seeking professional help from a therapist or counselor can also provide valuable support. If you need further assistance or have more questions, feel free to ask.',\n",
       "   'reference': {'must mention': ['Sadness', 'winter', 'reflection']}},\n",
       "  '42c27a6a-c8ec-4b13-a67e-dd3d668bd877': {'input': {'question': \"I’ve been with my boyfriend for a year and a half. He loves me a lot, and I love him. It hurts to be apart from him for so long. It hurts all over, and then I feel like it won't last.\"},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment='The criterion for this task is \"helpfulness\". \\n\\n1. The submission begins by acknowledging the emotional challenges of long-distance relationships and validates the feelings of the person who asked the question. This is helpful because it shows understanding and empathy.\\n\\n2. The submission then provides a list of practical suggestions for managing a long-distance relationship. These suggestions are insightful and appropriate, as they address the emotional challenges mentioned in the question and offer ways to cope with them.\\n\\n3. The submission ends by encouraging the person to seek professional help if needed and to ask more questions or share more details for further advice. This is helpful because it offers additional support and opens the door for further conversation.\\n\\nBased on these points, the submission is helpful, insightful, and appropriate. Therefore, it meets the criterion.\\n\\nY', correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('d3faa081-3f4a-4db6-a26e-af2aa934117d'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=1, value='CORRECT', comment=\"The student's answer is a comprehensive response to the question. It acknowledges the emotional distress the questioner is experiencing due to the long-distance relationship and provides practical advice on how to manage these feelings. The student's answer aligns with the context of 'Codependency', 'Emotions', and 'counseling'. The student suggests open communication, self-care, setting goals, seeking support, and reflecting on values as strategies to cope with the situation. The student also encourages the questioner to seek professional help if the emotional distress becomes overwhelming. Therefore, the student's answer is factually accurate and relevant to the context.\\nGRADE: CORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('7a2c996f-dc76-46fd-9f94-291115ecf9af'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('8bef50a5-5a3c-47c5-a1f9-1c2e9dd5bca0'), target_run_id=None)],\n",
       "   'execution_time': 8.387801,\n",
       "   'run_id': '70cbc0f2-de22-4c3c-a79d-5ad03bc37d6a',\n",
       "   'output': \"Observation: Long-distance relationships can have significant impacts on mental health, leading to feelings of loneliness, anxiety, and depression. Prioritizing communication, emotional support, and self-care is crucial for maintaining mental well-being in such situations.\\n\\nResponse:\\nIt's understandable that being apart from your boyfriend for an extended period can be emotionally challenging. The feelings of hurt and uncertainty you're experiencing are valid and common in long-distance relationships. Here are some empathetic yet practical suggestions to navigate this situation:\\n\\n1. **Open Communication:** Regular and honest communication with your boyfriend can help bridge the emotional gap and provide reassurance of your feelings for each other.\\n\\n2. **Self-Care:** Focus on self-care activities that bring you comfort and relaxation. Engage in hobbies, exercise, or mindfulness practices to nurture your mental well-being.\\n\\n3. **Set Goals:** Establish short-term and long-term goals for your relationship to create a sense of direction and purpose, helping you both stay connected and committed.\\n\\n4. **Seek Support:** Consider reaching out to trusted friends, family members, or a counselor to discuss your feelings and gain perspective on managing the challenges of a long-distance relationship.\\n\\n5. **Reflect on Values:** Reflect on your values and priorities in the relationship. Understanding what matters most to you can guide your decisions and actions in maintaining a healthy connection with your boyfriend.\\n\\nRemember, it's normal to feel the pain of separation, but with open communication, self-care, and support, you can navigate this challenging time together. If the emotional distress persists or becomes overwhelming, seeking professional help from a therapist or counselor can provide additional guidance and support.\\n\\nFeel free to ask more questions or share further details for tailored advice. You're not alone in this journey.\",\n",
       "   'reference': {'must mention': ['Codependency', 'Emotions', 'counseling']}},\n",
       "  '142f842a-0f77-4f47-a8d3-081e4c8f336f': {'input': {'question': \"My dad refuses to acknowledge my anxieties about going to parties, dinners, etc. Whenever I have an opinion it gets shut down. My mom and everyone else behaves likewise. For my father who heads a company, this is normal. He has to be right all the time. He blatantly refuses to even try to see it from my angle. \\r\\n\\r\\nRecently however, it's been getting to the point where I feel pressured and unable to speak my mind. It isn't possible for me to get professional one-on-one help. He tells me to grow a pair and get over it. I recently have been developing more severe body image and self-confidence issues, which I have had all my life. I feel invalidated by my dad.  I have been more paranoid lately as well. I can't turn on location services anymore on my phone because of a past incident. He makes me feel guilty about it.  I feel rather worthless more often than not, unfortunately.  What do I do?\"},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=1, value='Y', comment=\"The criterion for this task is the helpfulness of the submission. \\n\\nThe submission provides a detailed response to the input, offering several actionable steps that the individual can take to cope with their situation. These steps include seeking support, practicing self-care, setting boundaries, exploring online resources, and considering therapy. \\n\\nThe submission also validates the individual's feelings and emphasizes the importance of prioritizing their mental well-being. It offers a sense of understanding and support, which can be helpful for someone dealing with dismissive behavior from a parent regarding mental health concerns.\\n\\nThe submission is insightful as it provides a comprehensive approach to dealing with the situation. It not only addresses the immediate issue of the dismissive behavior from the parent but also provides long-term strategies for managing anxieties and self-confidence issues.\\n\\nThe submission is appropriate as it is respectful, empathetic, and supportive. It does not dismiss the individual's feelings or experiences but instead validates them and offers practical advice.\\n\\nBased on this analysis, the submission meets the criterion of being helpful, insightful, and appropriate.\\n\\nY\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('68a9c521-43f6-4645-adc7-52beb23a6360'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=1, value='CORRECT', comment=\"The student's answer is addressing the question by providing a detailed and thoughtful response. The student has identified the key issues in the question, such as the need for support, dealing with dismissive behavior, and managing anxieties and self-confidence issues. The student has also provided actionable steps that the person can take to address these issues, such as seeking support, practicing self-care, setting boundaries, exploring online resources, and considering therapy. The student's answer is factually accurate and aligns with the context provided. \\nGRADE: CORRECT\", correction=None, evaluator_info={'__run': RunInfo(run_id=UUID('3207b8fb-3ed2-4250-bde3-1b7918d71b46'))}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='must_mention', score=True, value=None, comment=None, correction=None, evaluator_info={}, feedback_config=None, source_run_id=UUID('3eae60c9-18c7-4f51-ae53-0d83b02d6e2c'), target_run_id=None)],\n",
       "   'execution_time': 8.073005,\n",
       "   'run_id': '7d21cd00-4fd7-442b-8516-d67a5da1d399',\n",
       "   'output': \"Observation: Seeking support from trusted individuals or mental health professionals can provide validation and guidance in coping with dismissive behavior from a parent regarding mental health concerns.\\n\\nAnswer: In your situation, it's essential to prioritize your mental well-being. Here are some actionable steps you can take:\\n\\n1. Seek Support: Reach out to a trusted friend, family member, or school counselor to talk about your feelings and experiences. Having someone who listens and validates your emotions can be incredibly helpful.\\n\\n2. Self-Care: Practice self-care activities that promote relaxation and self-compassion. This could include mindfulness exercises, journaling, or engaging in activities that bring you joy.\\n\\n3. Set Boundaries: Establish boundaries with your dad to protect your mental health. Communicate assertively about your needs and feelings, even if he may not fully understand at first.\\n\\n4. Explore Online Resources: Look for online resources or support groups that focus on mental health and coping with dismissive behavior. Connecting with others who have similar experiences can provide a sense of community and understanding.\\n\\n5. Consider Therapy: If professional one-on-one help is not immediately accessible, consider exploring online therapy options or self-help resources that can offer guidance and support in managing your anxieties and self-confidence issues.\\n\\nRemember, your feelings are valid, and it's important to prioritize your well-being. If you ever feel overwhelmed or in need of additional support, don't hesitate to reach out for help. You deserve to feel heard and supported in your journey towards mental wellness.\",\n",
       "   'reference': {'must mention': ['Anxiety', 'Professional help', 'support']}},\n",
       "  '326aea93-100c-47ec-aaa9-3c47439298ee': {'input': {'question': 'My wife and I have a great relationship except for our sex lives. We are pretty transparent and honest, and basically, she feels bad because she never wants to have sex. She doesn\\'t have the desire. She\\'s also never orgasmed. She feels like a terrible wife and fears I\\'ll cheat on her. She doesn\\'t know why. Last time we had sex, she cried and felt bad and didn\\'t know why she cried. However, she also told me that the last time we had sex, she felt me in her, but it just felt \"ehh\" and wanted to stop. That makes me feel really awful. We rarely have foreplay. Everything I try tickles her, so she makes me stop. We are both frustrated but very much in love. She and I are in our early 20s. We’re married and we have a baby on the way.'},\n",
       "   'feedback': [],\n",
       "   'execution_time': 5.076782,\n",
       "   'run_id': 'f542d0fd-ef2f-417c-99de-a02a64c4dd7d',\n",
       "   'Error': TypeError(\"PubmedQueryRun._run() got an unexpected keyword argument '__arg1'\"),\n",
       "   'reference': {'must mention': ['Pregnancy', 'Intimacy', 'therapy']}}},\n",
       " 'aggregate_metrics': None}"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[must_mention],\n",
    "    evaluators=[\n",
    "        \"criteria\",\n",
    "        \"cot_qa\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "#----------------------------\n",
    "# EVALUATING\n",
    "#----------------------------\n",
    "client.run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=agent_chain,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=f\"RAG Pipeline - Evaluation -{uuid4().hex[0:8]}\",\n",
    "    project_metadata={\"version\": \"1.0.0\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langraph with Helpfulness\n",
    "adding helpfulness check and loop : we review the content of the generate solutions and check if compared to the query it was helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  # messages: Annotated[list, add_messages]\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if \"function_call\" not in last_message.additional_kwargs:\n",
    "    return \"end\"\n",
    "\n",
    "  return \"continue\"\n",
    "\n",
    "def check_helpfulness(state):\n",
    "  initial_query=state['messages'][0]\n",
    "  final_response=state['messages'][-1]\n",
    "\n",
    "  # adding artificial_loop\n",
    "\n",
    "  if len(state[\"messages\"]) > 10:\n",
    "    return \"END\"\n",
    "\n",
    "  prompt_template = \"\"\"\\\n",
    "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y'\\\n",
    "  and unhelpfulness as an 'N'.\n",
    "\n",
    "  Initial Query:\n",
    "  {initial_query}\n",
    "\n",
    "  Final Response:\n",
    "  {final_response}\"\"\"\n",
    "\n",
    "  prompt_template=PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "  helpfulness_check_chain= prompt_template | helpfulness_check_model | StrOutputParser()\n",
    "\n",
    "  helpfulness_response= helpfulness_check_chain.invoke({\"initial_query\": initial_query, \"final_response\": final_response})\n",
    "\n",
    "  if \"Y\" in helpfulness_response:\n",
    "    print(\"helpful!\")\n",
    "    return \"end\"\n",
    "  \n",
    "  else:\n",
    "    print(\" Not helpful!!\")\n",
    "    return \"continue\"\n",
    "\n",
    "\n",
    "def dummy_node(state):\n",
    "  return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_update_bot_with_helpfullness_node(): \n",
    "    \n",
    "    graph_with_helpfulness_check = StateGraph(AgentState)\n",
    "\n",
    "    graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
    "    graph_with_helpfulness_check.add_node(\"action\", call_tool)\n",
    "    graph_with_helpfulness_check.add_node(\"passthrough\", dummy_node)\n",
    "\n",
    "    graph_with_helpfulness_check.set_entry_point(\"agent\")\n",
    "    \n",
    "    graph_with_helpfulness_check.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\" : \"action\",\n",
    "        \"end\" : \"passthrough\"\n",
    "    }\n",
    "    )\n",
    "\n",
    "    graph_with_helpfulness_check.add_conditional_edges(\n",
    "        \"passthrough\",\n",
    "        check_helpfulness,\n",
    "        {\n",
    "            \"continue\" : \"agent\",\n",
    "            \"end\" : END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    graph_with_helpfulness_check.add_edge(\"action\", \"agent\")\n",
    "\n",
    "    return graph_with_helpfulness_check.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7efba89c3ca0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7efba8aebe80>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'rag_tool', 'description': 'Use this tool to retrieve relevant information from the knowledge base.', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string'}}, 'required': ['question']}}, {'name': 'pub_med', 'description': 'A wrapper around PubMed. Useful for when you need to answer questions about medicine, health, and biomedical topics from biomedical literature, MEDLINE, life science journals, and online books. Input should be a search query.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}, {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}, {'name': 'duckduckgo_search', 'description': 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}]})"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_model(state):\n",
    "#   messages = state[\"messages\"]\n",
    "#   response = model.invoke(messages)\n",
    "#   return {\"messages\" : [response]}\n",
    "\n",
    "# def call_tool(state):\n",
    "#   last_message = state[\"messages\"][-1]\n",
    "\n",
    "#   action = ToolInvocation(\n",
    "#       tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "#       tool_input=json.loads(\n",
    "#           last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "#       )\n",
    "#   )\n",
    "\n",
    "#   response = tool_executor.invoke(action)\n",
    "\n",
    "#   function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "#   return {\"messages\" : [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages(messages):\n",
    "  next_is_tool = False\n",
    "  initial_query = True\n",
    "  for message in messages[\"messages\"]:\n",
    "    if \"function_call\" in message.additional_kwargs:\n",
    "      print()\n",
    "      print(f'Tool Call - Name: {message.additional_kwargs[\"function_call\"][\"name\"]} + Query: {message.additional_kwargs[\"function_call\"][\"arguments\"]}')\n",
    "      next_is_tool = True\n",
    "      continue\n",
    "    if next_is_tool:\n",
    "      print(f\"Tool Response: {message.content}\")\n",
    "      next_is_tool = False\n",
    "      continue\n",
    "    if initial_query:\n",
    "      print(f\"Initial Query: {message.content}\")\n",
    "      print()\n",
    "      initial_query = False\n",
    "      continue\n",
    "    print()\n",
    "    print(f\"Agent Response: {message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "bot_with_helpfulness_check=get_state_update_bot_with_helpfullness_node() # type: ignore\n",
    "\n",
    "try:\n",
    "    display(Image(bot_with_helpfulness_check.get_graph().draw_mermaid_png()))#state_update_bot\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpful!\n",
      "Initial Query: I feel depressed even though I act like a happy with my family. I act like I’m happy so my son doesn’t see me sad. I act like my life is a happy life, but I feel sad and depressed. I sometimes think of killing myself and that my family deserve someone better than me. I just cry and write in my book all these feelings.\n",
      "\n",
      "\n",
      "Agent Response: I'm sorry to hear that you're feeling this way. It's important to remember that you are not alone and there are people who care about you and want to help. It's brave of you to reach out and talk about your feelings. \n",
      "\n",
      "If you are having thoughts of harming yourself, it's crucial to seek help immediately. You can reach out to a mental health professional, a therapist, a counselor, or a helpline for support. Your well-being is important, and there are resources available to help you through this difficult time.\n",
      "\n",
      "If you're comfortable, I can provide you with some resources or information on how to cope with these feelings. Just let me know how I can assist you.\n"
     ]
    }
   ],
   "source": [
    "# bot_with_helpfulness_check=get_state_update_bot_with_helpfullness_node()\n",
    "\n",
    "inputs = {\"messages\" : [HumanMessage(content=mental_health_counseling_data['test'][12][\"Context\"])]}\n",
    "\n",
    "messages = bot_with_helpfulness_check.invoke(inputs)\n",
    "\n",
    "print_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It sounds like you have several different things happening at the same time. I would encourage you to call and speak to a local therapist. If you are having thoughts of killing yourself in this moment, please call 800-273-8255 and talk to someone.While I follow that you would like your son to be unaware of what you are going through, that doesn't mean that you can't discuss your feelings with someone else. Who is it that you trust or could speak with about this? A therapist could be one person, but perhaps there is someone else in your life as well.One thing that may help is to find a bead or rock that is smooth and you can hold onto it while thinking of a specific memory where you were happy. This could be from as long ago as necessary as long as it is specific and you can place yourself back in that time when you are thinking about it. If you think about this time while holding onto the bead, the bead may remind you of a time when you felt happy. You could do the same thing for a time when you felt comfortable and safe.Have you recognized any patterns for what is leading you to be sad?Can you think of anything that makes you feel good, even if it only works for a few minutes?\""
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mental_health_counseling_data['test'][12][\"Response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD systemPrompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpful!\n",
      "Initial Query: You are a qualified psychologist providing mental health advice. Be empathetic in your responses. \n",
      "    Always provide a complete response. Be empathetic and provide a follow-up question to find a resolution. \n",
      "    First, look up the RAG (retrieval-augmented generation) and then arxiv research or use InternetSearch:\n",
      "\n",
      "\n",
      "\n",
      "You will operate in a loop of Thought, Action, PAUSE, and Observation. At the end of the loop, you will provide an Answer.\n",
      "\n",
      "Instructions:\n",
      "\n",
      "Thought: Describe your thoughts about the user's question.\n",
      "Action: Choose one of the available actions to gather information or provide insights.\n",
      "PAUSE: Pause to allow the action to complete.\n",
      "Observation: Review the results of the action.\n",
      "\n",
      "Available Actions:\n",
      "\n",
      "Use the tools at your disposal to look up information or resolve the consultancy. You are allowed to make multiple calls (either together or in sequence).:\n",
      "\n",
      "    1. rag_tool: RAG (Retrieval-Augmented Generation) to access relevant mental health information.\n",
      "    2. DuckDuckGoSearchRun: Perform an online search: InternetSearch to find up-to-date resources and recommendations.\n",
      "    3. ArxivQueryRun: Find relevant research or content.\n",
      "    3. PubMedQuerRun: Find a specific coping strategies or management techniques by doing research paper\n",
      "\n",
      "    You may make multiple calls to these tools as needed to provide comprehensive advice.\n",
      "\n",
      "    Present your final response in a clear, structured format, including a chart of recommended actions if appropriate.\n",
      "\n",
      "    User's question: I have several issues like I don't like people. They make me sick. I have issues with talking to people. I feel like they are talking about me and making fun of me. I have felt this way for years. When I look people in the eyes I have voices that tell me to hurt them and if I don't stop looking at who I am talking to it gets so loud I can't hear what they are saying. I just stay away from people to avoid this. I look at people and think how I could hurt them. I feel like I am worthless and would be better off not in this world where I don't fit in. Every day I wake up it's like another day. Any info would be good.\n",
      "\n",
      "    Response: Your task is When responding to users' personal issues or concerns:\n",
      "\n",
      "1. With a brief empathetic acknowledgment of the user's situation, continue\n",
      "2. Provide practical, actionable advice that often includes \n",
      "3. Suggesting professional help (e.g., therapists, counselors) when appropriate\n",
      "4. Encouraging open communication and dialogue with involved parties and \n",
      "5. Recommending self-reflection or exploration of emotions and values and\n",
      "6. Offering specific coping strategies or management techniques\n",
      "\n",
      "\n",
      "\n",
      "Tool Call - Name: rag_tool + Query: {\"question\":\"mental health issues related to social anxiety and violent thoughts\"}\n",
      "Tool Response: I don't know.\n",
      "\n",
      "Tool Call - Name: arxiv + Query: {\"query\":\"social anxiety and violent thoughts\"}\n",
      "Tool Response: Published: 2021-08-31\n",
      "Title: Network psychometrics and cognitive network science open new ways for detecting, understanding and tackling the complexity of math anxiety: A review\n",
      "Authors: Massimo Stella\n",
      "Summary: Math anxiety is a clinical pathology impairing cognitive processing in\n",
      "math-related contexts. Originally thought to affect only inexperienced,\n",
      "low-achieving students, recent investigations show how math anxiety is vastly\n",
      "diffused even among high-performing learners. This review of data-informed\n",
      "studies outlines math anxiety as a complex system that: (i) cripples\n",
      "well-being, self-confidence and information processing on both conscious and\n",
      "subconscious levels, (ii) can be transmitted by social interactions, like a\n",
      "pathogen, and worsened by distorted perceptions, (iii) affects roughly 20% of\n",
      "students in 63 out of 64 worldwide educational systems but correlates weakly\n",
      "with academic performance, and (iv) poses a concrete threat to students'\n",
      "well-being, computational literacy and career prospects in science. These\n",
      "patterns underline the crucial need to go beyond performance for estimating\n",
      "math anxiety. Recent advances with network psychometrics and cognitive network\n",
      "science provide ideal frameworks for detecting, interpreting and intervening\n",
      "upon such clinical condition. Merging education research, psychology and data\n",
      "science, the approaches reviewed here reconstruct psychological constructs as\n",
      "complex systems, represented either as multivariate correlation models (e.g.\n",
      "graph exploratory analysis) or as cognitive networks of semantic/emotional\n",
      "associations (e.g. free association networks or forma mentis networks). Not\n",
      "only can these interconnected networks detect otherwise hidden levels of math\n",
      "anxiety but - more crucially - they can unveil the specific layout of\n",
      "interacting factors, e.g. key sources and targets, behind math anxiety in a\n",
      "given cohort. As discussed here, these network approaches open concrete ways\n",
      "for unveiling students' perceptions, emotions and mental well-being, and can\n",
      "enable future powerful data-informed interventions untangling math anxiety.\n",
      "\n",
      "Published: 2024-02-17\n",
      "Title: Detecting a Proxy for Potential Comorbid ADHD in People Reporting Anxiety Symptoms from Social Media Data\n",
      "Authors: Claire S. Lee, Noelle Lim, Michael Guerzhoy\n",
      "Summary: We present a novel task that can elucidate the connection between anxiety and\n",
      "ADHD; use Transformers to make progress toward solving a task that is not\n",
      "solvable by keyword-based classifiers; and discuss a method for visualization\n",
      "of our classifier illuminating the connection between anxiety and ADHD\n",
      "presentations.\n",
      "  Up to approximately 50% of adults with ADHD may also have an anxiety disorder\n",
      "and approximately 30\\% of adults with anxiety may also have ADHD. Patients\n",
      "presenting with anxiety may be treated for anxiety without ADHD ever being\n",
      "considered, possibly affecting treatment. We show how data that bears on ADHD\n",
      "that is comorbid with anxiety can be obtained from social media data, and show\n",
      "that Transformers can be used to detect a proxy for possible comorbid ADHD in\n",
      "people with anxiety symptoms.\n",
      "  We collected data from anxiety and ADHD online forums (subreddits). We\n",
      "identified posters who first started posting in the Anxiety subreddit and later\n",
      "started posting in the ADHD subreddit as well. We use this subset of the\n",
      "posters as a proxy for people who presented with anxiety symptoms and then\n",
      "became aware that they might have ADHD. We fine-tune a Transformer\n",
      "architecture-based classifier to classify people who started posting in the\n",
      "Anxiety subreddit and then started posting in the ADHD subreddit vs. people who\n",
      "posted in the Anxiety subreddit without later posting in the ADHD subreddit. We\n",
      "show that a Transformer architecture is capable of achieving reasonable results\n",
      "(76% correct for RoBERTa vs. under 60% correct for the best keyword-based\n",
      "model, both with 50% base rate).\n",
      "\n",
      "Published: 2019-09-13\n",
      "Title: Feeling Anxious? Perceiving Anxiety in Tweets using Machine Learning\n",
      "\n",
      "\n",
      "Agent Response: I understand that you are experiencing significant challenges with social interactions and violent thoughts, which have been affecting you for years. It's important to acknowledge the distress and discomfort you are feeling in these situations.\n",
      "\n",
      "Based on recent research, there is a connection between social anxiety and violent thoughts. Studies have shown that social anxiety can manifest in various ways, including intrusive thoughts and negative perceptions of others. It's essential to address these issues to improve your well-being and quality of life.\n",
      "\n",
      "Here are some steps you can consider to help manage these difficulties:\n",
      "\n",
      "1. Seek Professional Help: Consider reaching out to a mental health professional, such as a therapist or counselor, who can provide you with support and guidance in addressing your social anxiety and violent thoughts.\n",
      "\n",
      "2. Practice Mindfulness and Relaxation Techniques: Engaging in mindfulness practices and relaxation techniques, such as deep breathing exercises or meditation, can help reduce anxiety and promote a sense of calm.\n",
      "\n",
      "3. Challenge Negative Thoughts: Work on challenging and reframing negative thoughts that contribute to your feelings of worthlessness and isolation. Cognitive-behavioral therapy (CBT) can be beneficial in addressing these thought patterns.\n",
      "\n",
      "4. Build a Support System: Surround yourself with supportive and understanding individuals who can offer encouragement and empathy during challenging times.\n",
      "\n",
      "5. Engage in Self-Care Activities: Take time for self-care activities that bring you joy and relaxation. This can include hobbies, exercise, spending time in nature, or engaging in creative outlets.\n",
      "\n",
      "It's important to remember that you are not alone in facing these challenges, and there are resources and strategies available to help you navigate through this difficult time. If you ever feel overwhelmed or in crisis, please reach out to a mental health professional or a crisis helpline for immediate support.\n",
      "\n",
      "Would you be open to exploring therapy or counseling as a step towards addressing these issues and improving your well-being?\n"
     ]
    }
   ],
   "source": [
    "def convert_inputs(input_object):\n",
    "    system_prompt = f\"\"\"You are a qualified psychologist providing mental health advice. Be empathetic in your responses. \n",
    "    Always provide a complete response. Be empathetic and provide a follow-up question to find a resolution. \n",
    "    First, look up the RAG (retrieval-augmented generation) and then arxiv research or use InternetSearch:\n",
    "\n",
    "\n",
    "\n",
    "You will operate in a loop of Thought, Action, PAUSE, and Observation. At the end of the loop, you will provide an Answer.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Thought: Describe your thoughts about the user's question.\n",
    "Action: Choose one of the available actions to gather information or provide insights.\n",
    "PAUSE: Pause to allow the action to complete.\n",
    "Observation: Review the results of the action.\n",
    "\n",
    "Available Actions:\n",
    "\n",
    "Use the tools at your disposal to look up information or resolve the consultancy. You are allowed to make multiple calls (either together or in sequence).:\n",
    "\n",
    "    1. rag_tool: RAG (Retrieval-Augmented Generation) to access relevant mental health information.\n",
    "    2. DuckDuckGoSearchRun: Perform an online search: InternetSearch to find up-to-date resources and recommendations.\n",
    "    3. ArxivQueryRun: Find relevant research or content.\n",
    "    3. PubMedQuerRun: Find a specific coping strategies or management techniques by doing research paper\n",
    "\n",
    "    You may make multiple calls to these tools as needed to provide comprehensive advice.\n",
    "\n",
    "    Present your final response in a clear, structured format, including a chart of recommended actions if appropriate.\n",
    "\n",
    "    User's question: {input_object['question']}\n",
    "\n",
    "    Response: Your task is When responding to users' personal issues or concerns:\n",
    "\n",
    "1. With a brief empathetic acknowledgment of the user's situation, continue\n",
    "2. Provide practical, actionable advice that often includes \n",
    "3. Suggesting professional help (e.g., therapists, counselors) when appropriate\n",
    "4. Encouraging open communication and dialogue with involved parties and \n",
    "5. Recommending self-reflection or exploration of emotions and values and\n",
    "6. Offering specific coping strategies or management techniques\n",
    "\"\"\"\n",
    "    return {\"messages\": [HumanMessage(content=system_prompt)]}\n",
    "\n",
    "# Define the function to parse the output\n",
    "def parse_output(input_state):\n",
    "    return input_state[\"messages\"][-1].content\n",
    "\n",
    "bot_with_helpfulness_check=get_state_update_bot_with_helpfullness_node() # type: ignore\n",
    "# Create the agent chain\n",
    "agent_chain = convert_inputs | bot_with_helpfulness_check# | StrOutputParser()#| parse_output\n",
    "\n",
    "# Run the agent chain with the input\n",
    "messages=agent_chain.invoke({\"question\": mental_health_counseling_data['test'][14]['Context']})\n",
    "print_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I understand that you are experiencing significant challenges with social interactions and violent thoughts, which have been affecting you for years. It's important to acknowledge the distress and discomfort you are feeling in these situations.\\n\\nBased on recent research, there is a connection between social anxiety and violent thoughts. Studies have shown that social anxiety can manifest in various ways, including negative perceptions of social interactions and distorted beliefs about how others perceive you. These feelings can contribute to the development of violent thoughts or impulses.\\n\\nIt's crucial to address these concerns and seek support to improve your mental well-being. Here are some steps you can consider:\\n\\n1. Seek Professional Help: Consider reaching out to a mental health professional, such as a therapist or counselor, who can provide you with guidance and support in managing social anxiety and violent thoughts.\\n\\n2. Practice Self-Compassion: Be kind to yourself and recognize that these thoughts and feelings are challenging. Engage in self-care activities that promote relaxation and self-compassion.\\n\\n3. Challenge Negative Thoughts: Work on challenging and reframing negative thoughts that contribute to feelings of worthlessness and isolation. Cognitive-behavioral therapy (CBT) can be helpful in addressing these thought patterns.\\n\\n4. Explore Coping Strategies: Identify healthy coping strategies that can help you manage stress and anxiety. This may include mindfulness techniques, deep breathing exercises, or engaging in activities that bring you joy.\\n\\n5. Build a Support System: Reach out to trusted friends or family members who can provide emotional support and understanding. Opening up about your struggles can help alleviate feelings of loneliness and isolation.\\n\\nRemember, you are not alone in facing these challenges, and there are resources and support available to help you navigate through this difficult time. It's essential to prioritize your mental health and well-being. If you ever feel overwhelmed or in crisis, please consider contacting a mental health hotline or emergency services for immediate assistance.\\n\\nWould you be open to exploring therapy or counseling as a step towards addressing these concerns and improving your mental health?\""
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['messages'][-1].content#find('Agent Response:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainlit?? How to deploy and what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import chainlit as cl\n",
    "\n",
    "@cl.author_rename\n",
    "def rename(original_author: str):\n",
    "    \"\"\"\n",
    "    This function can be used to rename the 'author' of a message. \n",
    "\n",
    "    In this case, we're overriding the 'Assistant' author to be 'Paul Graham Essay Bot'.\n",
    "    \"\"\"\n",
    "    rename_dict = {\n",
    "        \"Assistant\" : \"Mental Health Advisor Bot\"\n",
    "    }\n",
    "    return rename_dict.get(original_author, original_author)\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def start_chat():\n",
    "    \"\"\"\n",
    "    This function will be called at the start of every user session. \n",
    "\n",
    "    We will build our LCEL RAG chain here, and store it in the user session. \n",
    "\n",
    "    The user session is a dictionary that is unique to each user session, and is stored in the memory of the server.\n",
    "    \"\"\"\n",
    "\n",
    "    ### BUILD LCEL RAG CHAIN THAT ONLY RETURNS TEXT\n",
    "    # lcel_rag_chain = ( {\"context\": itemgetter(\"query\") | hf_retriever, \"query\": itemgetter(\"query\")}\n",
    "                      \n",
    "    #                    | rag_prompt | hf_llm\n",
    "    #                 )\n",
    "    bot_with_helpfulness_check=get_state_update_bot_with_helpfullness_node() # type: ignore\n",
    "    lcel_rag_chain = convert_inputs | bot_with_helpfulness_check\n",
    "\n",
    "    cl.user_session.set(\"lcel_rag_chain\", lcel_rag_chain)\n",
    "\n",
    "@cl.on_message  \n",
    "async def main(message: cl.Message):\n",
    "    \"\"\"\n",
    "    This function will be called every time a message is recieved from a session.\n",
    "\n",
    "    We will use the LCEL RAG chain to generate a response to the user query.\n",
    "\n",
    "    The LCEL RAG chain is stored in the user session, and is unique to each user session - this is why we can access it here.\n",
    "    \"\"\"\n",
    "    lcel_rag_chain = cl.user_session.get(\"lcel_rag_chain\")\n",
    "\n",
    "    msg = cl.Message(content=\"\")\n",
    "\n",
    "    async for chunk in lcel_rag_chain.astream(\n",
    "        {\"question\": message.content},\n",
    "        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),\n",
    "    ):\n",
    "        await msg.stream_token(chunk)\n",
    "\n",
    "    await msg.send()\n",
    "\n",
    "# chainlit run app.py -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install chainlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-17 10:55:58 - Created default config file at /home/sahane/AIE3/Week 5/Day 2/.chainlit/config.toml\n",
      "2024-07-17 10:56:02 - Loaded .env file\n"
     ]
    }
   ],
   "source": [
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add first action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_update_bot_with_helpfullness_node(): \n",
    "    \n",
    "    graph_with_helpfulness_check = StateGraph(AgentState)\n",
    "\n",
    "    graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
    "    graph_with_helpfulness_check.add_node(\"action\", call_tool)\n",
    "    graph_with_helpfulness_check.add_node(\"passthrough\", dummy_node)\n",
    "\n",
    "    graph_with_helpfulness_check.set_entry_point(\"agent\")\n",
    "    \n",
    "    graph_with_helpfulness_check.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\" : \"action\",\n",
    "        \"end\" : \"passthrough\"\n",
    "    }\n",
    "    )\n",
    "\n",
    "    graph_with_helpfulness_check.add_conditional_edges(\n",
    "        \"passthrough\",\n",
    "        check_helpfulness,\n",
    "        {\n",
    "            \"continue\" : \"agent\",\n",
    "            \"end\" : END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    graph_with_helpfulness_check.add_edge(\"action\", \"agent\")\n",
    "\n",
    "    return graph_with_helpfulness_check.compile()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
